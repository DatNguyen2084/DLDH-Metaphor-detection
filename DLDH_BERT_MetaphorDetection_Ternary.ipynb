{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DatNguyen2084/DLDH-Metaphor-detection/blob/main/DLDH_BERT_MetaphorDetection_Ternary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v5Kc9Y4qFix"
      },
      "source": [
        "# DLDH Seminar - Metaphor Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKVPGsoRZZgw"
      },
      "source": [
        "Classifying metaphors, metaphor candidates and non-metaphors using BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RNDhnNzvXmK"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE69Grt8mKtn",
        "outputId": "42e11b3d-9379-4333-f92f-eaca55c18329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 79 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 12.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 16.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 23.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 28.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.2 MB/s \n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 325 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 42.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 47.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 134 kB 49.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 45.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 51.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 49.1 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hCollecting deepl\n",
            "  Downloading deepl-1.5.0-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.7/dist-packages (from deepl) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2->deepl) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2->deepl) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2->deepl) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2->deepl) (1.25.11)\n",
            "Installing collected packages: deepl\n",
            "Successfully installed deepl-1.5.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q sentence_transformers\n",
        "!pip install -q datasets\n",
        "!pip install --upgrade deepl\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpTOGzcFpjM8"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import copy\n",
        "import csv\n",
        "import glob\n",
        "import json\n",
        "import random\n",
        "import transformers\n",
        "from datetime import datetime\n",
        "\n",
        "import deepl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
        "from torch import nn\n",
        "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
        "from transformers import (AutoConfig, AutoModelForSequenceClassification,\n",
        "                          AutoTokenizer, BertForSequenceClassification,\n",
        "                          BertModel, Trainer, TrainingArguments)\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from transformers.models.bert.modeling_bert import *\n",
        "from transformers.utils.dummy_tf_objects import TFDPRQuestionEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnvkz8Ervl91"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj4eEFykolOU",
        "outputId": "7a760f55-8af2-4f41-f291-6b9e8bbca850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "# The following data is needed: https://drive.google.com/drive/folders/159CN2MDaGLzuoiA7x--Qq5zEdPavFcpf?usp=sharing\n",
        "# Create a shortcut to your Drive (\"Drive-Verknüpfung hinzufügen\" zu \"Meine Ablage\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEr6NOpeo6Ds"
      },
      "outputs": [],
      "source": [
        "ROOT_PATH = '/content/drive/MyDrive/DLDH'\n",
        "DATA_PATH = '/data'\n",
        "MODEL_PATH = '/model'\n",
        "RESULTS_PATH = '/results'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjQ-_uf_qzQ8"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Oversampling"
      ],
      "metadata": {
        "id": "u2NwgEdLSDAI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbsSVjQviEOx"
      },
      "outputs": [],
      "source": [
        "# If this parameter is set on true, oversampling will be performed on the dataframe\n",
        "oversample_dataframe = False\n",
        "\n",
        "# For the use of the Deepl API (is used to oversample the data set), a Deepl Authentication Key is needed\n",
        "# To obtain such a key, a free trial can be started on the following page: https://www.deepl.com/docs-api/\n",
        "# When 500.000 characters have been translated, a credit card is needed to start a real abonnement and to access the API\n",
        "deepl_auth_key = 'DEEPL_AUTH_KEY'\n",
        "\n",
        "# This parameter specifies the number of iterations after which the intermediate result of the dataframe should be stored repeatedly\n",
        "backup_oversampled_dataframe_after_rows = 40\n",
        "\n",
        "def set_default_staerkegrad_df(df):\n",
        "  \"\"\" \n",
        "  set_default_staerkegrad accepts a dataframe as input. Checks if there is a column named \"Staerkegrad\"\n",
        "  and if there is inserts into empty fields in that column the mostly used value from the column.\n",
        "\n",
        "  :param df: a pandas dataframe\n",
        "  :return: a pandas dataframe, where for every undefined entry in the column \"Staerkgegrad\" the most common value from all rows is set. If there is no such column in the input dataframe, the input dataframe is returned.  \n",
        "  \"\"\"\n",
        "  if ('Stärkegrad (A, B, C)' not in df.columns):\n",
        "    print('[set_default_staerkegrad_df]: Given dataframe does not consist of a column \"Staerkegrad\"!')\n",
        "    return df\n",
        "  else:\n",
        "    most_used_staerkegrad = df['Stärkegrad (A, B, C)'].value_counts().index[0]\n",
        "    df.fillna(value={'Stärkegrad (A, B, C)': most_used_staerkegrad})\n",
        "    return df\n",
        "\n",
        "def translate(text, target_language):\n",
        "  \"\"\"\n",
        "  translate translates the input text into the target language.\n",
        "\n",
        "  :param text: the text to be translated\n",
        "  :param target_language: the deepl target language expression, examples are 'DE' or 'EN-US'\n",
        "  :return: a string, the translation of :param text into the :param target_language\n",
        "  \"\"\"\n",
        "  translator = deepl.Translator(deepl_auth_key) \n",
        "  result = translator.translate_text(text, target_lang=target_language) \n",
        "  translated_text = result.text\n",
        "  return translated_text\n",
        "\n",
        "def translate_into_english_and_back(text):\n",
        "  \"\"\"\n",
        "  translate_into_english_and_back translates the input text into english and then into German.\n",
        "\n",
        "  :param text: the text to be translated\n",
        "  :return: a string. Returned is the result from translating :param text into englisch and after that into German.\n",
        "  \"\"\"\n",
        "  translator = deepl.Translator(deepl_auth_key) \n",
        "  result_eng = translator.translate_text(text, target_lang='EN-US')\n",
        "  result_ger = translator.translate_text(result_eng.text, target_lang='DE')\n",
        "  return result_ger.text\n",
        "\n",
        "def translate_into_target_language_and_back(text, target_language):\n",
        "  \"\"\"\n",
        "  translate_into_target_language_and_back translates the input text into the given target_language and then into German.\n",
        "\n",
        "  :param text: the text to be translated\n",
        "  :param target_language: the language\n",
        "  :return: a string. Returned is the result from translating :param text into :param target_language and then into German. \n",
        "  \"\"\"\n",
        "  translator = deepl.Translator(deepl_auth_key) \n",
        "  result_eng = translator.translate_text(text, target_lang=target_language)\n",
        "  result_ger = translator.translate_text(result_eng.text, target_lang='DE')\n",
        "  return result_ger.text\n",
        "\n",
        "def oversample_dataframe(df):\n",
        "  \"\"\"\n",
        "  Accepts a dataframe and returns the dataframe with oversampled data. The function was written for the known dataset of the Goldstandard. \n",
        "  In detail, every Textstelle (from metaphors only) from the input dataframe is taken, translated into four languages (english, spanish, czech and polish) and back into German.\n",
        "  By this way, for each Textstelle from :param df, four new texts are generated and added to the output dataframe. \n",
        "\n",
        "  :param df: a pandas dataframe. \n",
        "  :return: a pandas dataframe. In the output dataframe, four columns have been added, in which the different back and forth translated German texts are. \n",
        "  \"\"\"\n",
        "  # Before the oversampling, the counts of unique rows in the input df and of rows which are metaphors are printed\n",
        "  print('Ausprägungen und Anzahl Werte für gold_standard_df vor Oversampling:', df['Metapher?'].value_counts())\n",
        "  print('Metaphern im gold_standard_df vor Oversampling', df['Metapher?'].value_counts().Metapher)\n",
        "\n",
        "  # To backup interim results, this counter is initialized\n",
        "  count = 1\n",
        "\n",
        "  # To keep count of successfully added translated metaphor texts, the following counter is initialized\n",
        "  count_successfully_added_metaphor_texts = 0\n",
        "\n",
        "  # Split the input dataframe into two dataframes, one containing only metaphors and one with only not metaphors\n",
        "  only_metaphor_df = df[(df['Metapher?'] == 'Metapher')]\n",
        "  no_metaphors_df = df[(df['Metapher?'] != 'Metapher')]\n",
        "\n",
        "  # To the dataframe containing only metaphors, add four columns where the newly generated texts can be inserted to\n",
        "  only_metaphor_df['Synonym (aus Englischem)'] = \"\"\n",
        "  only_metaphor_df['Synonym (aus Spanischem)'] = \"\"\n",
        "  only_metaphor_df['Synonym (aus Tchechischem)'] = \"\"\n",
        "  only_metaphor_df['Synonym (aus Polnischem)'] = \"\"\n",
        "  \n",
        "  # Loop over all rows in the dataframe containing only metaphors and translate the text back and forth and insert the German result in the correct dataframe cell\n",
        "  for index, row in only_metaphor_df.iterrows():\n",
        "    text = row['Textstelle']\n",
        "    row['Synonym (aus Englischem)'] = translate_into_target_language_and_back(text, 'EN-US')\n",
        "    row['Synonym (aus Spanischem)'] = translate_into_target_language_and_back(text, 'ES')\n",
        "    row['Synonym (aus Tchechischem)'] = translate_into_target_language_and_back(text, 'CS')\n",
        "    row['Synonym (aus Polnischem)'] = translate_into_target_language_and_back(text, 'PL')\n",
        "    count_successfully_added_metaphor_texts += 4\n",
        "    print('working, count:', count)\n",
        "\n",
        "    # Backup interim results of the dataframe as csv files every 'backup_oversampled_dataframe_after_rows' iterations\n",
        "    if (count % backup_oversampled_dataframe_after_rows == 0): \n",
        "      only_metaphor_df.to_csv('only_metaphor_df_four_languages_backup_iteration_' + str(count) + '.csv', index=False)\n",
        "\n",
        "    # Increase counter\n",
        "    count+=1\n",
        "\n",
        "  # After the for loop, the two dataframes only metaphor and not metaphors need to get concatenated again\n",
        "  oversampled_data_df = only_metaphor_df.append(no_metaphors_df)\n",
        "\n",
        "  # After the oversampling, print the counts of unique rows in the oversampled dataframe and of rows which are metaphors again to get an overview on the results of the data augmentation \n",
        "  print('Ausprägungen und Anzahl Werte für gold_standard_df nach Oversampling:', oversampled_data_df['Metapher?'].value_counts())\n",
        "  print('Metaphern im gold_standard_df nach Oversampling', oversampled_data_df['Metapher?'].value_counts().Metapher + count_successfully_added_metaphor_texts)\n",
        "\n",
        "  return oversampled_data_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Saving Settings"
      ],
      "metadata": {
        "id": "fk4hNRN8SHie"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wXBs1Vk2J9m"
      },
      "outputs": [],
      "source": [
        "def save_settings(path, annotators, epochs, folds, model_type, oversampling, smote, comment):\n",
        "  \"\"\"\n",
        "  Saves the given settings to a text file at a given path\n",
        "  :param path: the path to output the text file to\n",
        "  :param annotators: The annotators to save \n",
        "  :param epochs: The number of epochs to save \n",
        "  :param folds: The number of folds to save \n",
        "  :param model_type: The model type to save \n",
        "  :param oversampling: The boolean if oversampling is activated \n",
        "  :param smote: The K for SMOTE to save \n",
        "  :param comment: A free comment to save in the text file\n",
        "  \"\"\"  \n",
        "  \n",
        "  lines = []\n",
        "  lines.append('Annotators: ' + ', '.join(annotators))\n",
        "  lines.append('Epochs: ' + str(epochs))\n",
        "  lines.append('Folds: ' + str(folds))\n",
        "  lines.append('Model Type: ' + model_type)\n",
        "  lines.append('Oversampling: ' + (\"On\" if oversampling else \"Off\"))\n",
        "  lines.append('SMOTE: ' + ((\"On (K=\"+str(smote)+\")\") if smote>0 else \"Off\"))\n",
        "  lines.append('Comment: ' + comment)\n",
        "\n",
        "  with open(path+'/settings.txt', 'w') as f: \n",
        "    f.write('\\n'.join(lines))\n",
        "\n",
        "  print(\"Settings saved to\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9x-fkUjpWNB"
      },
      "source": [
        "### Load Annotated Data (positive and negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvM387DUpb5q",
        "outputId": "f610046a-1ebc-4d2c-c326-5db5e6981434"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Seite                                         Textstelle  \\\n",
              "0      NaN   Bei Beobachtung solchen moralischen Wertes ka...   \n",
              "1      NaN               Die Zellen verschmelzen miteinander.   \n",
              "2      NaN   Diese wolle die bittere Auslese, ohne die auc...   \n",
              "3      NaN   Wenn es dem Verfasser gelungen ist, ein gesic...   \n",
              "4      NaN   In Californien ist ebenso die früher dort hei...   \n",
              "...    ...                                                ...   \n",
              "2579   NaN  In ähnlicher Weise sollen noch mehrere andere ...   \n",
              "2580   NaN  Die Amerikaner folgern, da sie alle Rohmateria...   \n",
              "2581   NaN  Sie könne bei ihrer jetzigen großen Kraft und ...   \n",
              "2582   NaN  Schwarze Flecken von Habgier, Raubsucht, Unger...   \n",
              "2583   NaN  Die Organisation, wie das natürlich ist, geht ...   \n",
              "\n",
              "              Metapher?                                              Fokus  \\\n",
              "0              Metapher                               das Horoskop stellen   \n",
              "1     Metaphernkandidat                                                NaN   \n",
              "2              Metapher                                            bittere   \n",
              "3              Metapher  ein gesichertes Fundament und die ersten Pfeil...   \n",
              "4     Metaphernkandidat                                                NaN   \n",
              "...                 ...                                                ...   \n",
              "2579  Metaphernkandidat                                                NaN   \n",
              "2580           Metapher                              einer turmhohen Mauer   \n",
              "2581           Metapher                         mütterlichen Päppelflasche   \n",
              "2582  Metaphernkandidat                                                NaN   \n",
              "2583  Metaphernkandidat                                                NaN   \n",
              "\n",
              "                                                 Rahmen Stärkegrad (A, B, C)  \\\n",
              "0                                          einer Nation                    B   \n",
              "1                                                   NaN                  NaN   \n",
              "2                                               Auslese                    A   \n",
              "3     die Lösung der hier zur Bearbeitung gestellten...                    A   \n",
              "4                                                   NaN                  NaN   \n",
              "...                                                 ...                  ...   \n",
              "2579                                                NaN                  NaN   \n",
              "2580                                       Schutzzöllen                    A   \n",
              "2581                                                Sie                    B   \n",
              "2582                                                NaN                  NaN   \n",
              "2583                                                NaN                  NaN   \n",
              "\n",
              "                                   Begründung/Kommentar Annotator Unnamed: 2  \\\n",
              "0     Horoskop stellen - bezogen auf Nationen ist da...         B        NaN   \n",
              "1                                          Fachausdruck         B        NaN   \n",
              "2     Unauffällig, aber doch metaphorisch: Dass eine...         B        NaN   \n",
              "3     Bruch, Fokus nicht ohne Bedeutungsverlust erse...         B        NaN   \n",
              "4     kein Bruch, nur auffälliger Ausdruck, keine Be...         B        NaN   \n",
              "...                                                 ...       ...        ...   \n",
              "2579                                                NaN         B        NaN   \n",
              "2580                                                NaN         B        NaN   \n",
              "2581                                                NaN         B        NaN   \n",
              "2582                                                NaN         B        NaN   \n",
              "2583                                                NaN         B        NaN   \n",
              "\n",
              "     Semantikerweiterung? Unersetzlich? sprachlich irregulär? pointiert?  \n",
              "0                     NaN           NaN                   NaN        NaN  \n",
              "1                     NaN           NaN                   NaN        NaN  \n",
              "2                     NaN           NaN                   NaN        NaN  \n",
              "3                     NaN           NaN                   NaN        NaN  \n",
              "4                     NaN           NaN                   NaN        NaN  \n",
              "...                   ...           ...                   ...        ...  \n",
              "2579                  NaN           NaN                   NaN        NaN  \n",
              "2580                  NaN           NaN                   NaN        NaN  \n",
              "2581                  NaN           NaN                   NaN        NaN  \n",
              "2582                  NaN           NaN                   NaN        NaN  \n",
              "2583                  NaN           NaN                   NaN        NaN  \n",
              "\n",
              "[2566 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc3ea82b-caae-4dcd-b2c1-204d7023bbcc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Seite</th>\n",
              "      <th>Textstelle</th>\n",
              "      <th>Metapher?</th>\n",
              "      <th>Fokus</th>\n",
              "      <th>Rahmen</th>\n",
              "      <th>Stärkegrad (A, B, C)</th>\n",
              "      <th>Begründung/Kommentar</th>\n",
              "      <th>Annotator</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Semantikerweiterung?</th>\n",
              "      <th>Unersetzlich?</th>\n",
              "      <th>sprachlich irregulär?</th>\n",
              "      <th>pointiert?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Bei Beobachtung solchen moralischen Wertes ka...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>das Horoskop stellen</td>\n",
              "      <td>einer Nation</td>\n",
              "      <td>B</td>\n",
              "      <td>Horoskop stellen - bezogen auf Nationen ist da...</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Die Zellen verschmelzen miteinander.</td>\n",
              "      <td>Metaphernkandidat</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fachausdruck</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Diese wolle die bittere Auslese, ohne die auc...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>bittere</td>\n",
              "      <td>Auslese</td>\n",
              "      <td>A</td>\n",
              "      <td>Unauffällig, aber doch metaphorisch: Dass eine...</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Wenn es dem Verfasser gelungen ist, ein gesic...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>ein gesichertes Fundament und die ersten Pfeil...</td>\n",
              "      <td>die Lösung der hier zur Bearbeitung gestellten...</td>\n",
              "      <td>A</td>\n",
              "      <td>Bruch, Fokus nicht ohne Bedeutungsverlust erse...</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>In Californien ist ebenso die früher dort hei...</td>\n",
              "      <td>Metaphernkandidat</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>kein Bruch, nur auffälliger Ausdruck, keine Be...</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2579</th>\n",
              "      <td>NaN</td>\n",
              "      <td>In ähnlicher Weise sollen noch mehrere andere ...</td>\n",
              "      <td>Metaphernkandidat</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2580</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Die Amerikaner folgern, da sie alle Rohmateria...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>einer turmhohen Mauer</td>\n",
              "      <td>Schutzzöllen</td>\n",
              "      <td>A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2581</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Sie könne bei ihrer jetzigen großen Kraft und ...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>mütterlichen Päppelflasche</td>\n",
              "      <td>Sie</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2582</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Schwarze Flecken von Habgier, Raubsucht, Unger...</td>\n",
              "      <td>Metaphernkandidat</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2583</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Die Organisation, wie das natürlich ist, geht ...</td>\n",
              "      <td>Metaphernkandidat</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2566 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc3ea82b-caae-4dcd-b2c1-204d7023bbcc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc3ea82b-caae-4dcd-b2c1-204d7023bbcc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc3ea82b-caae-4dcd-b2c1-204d7023bbcc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Loading annotated data for individual annotators\n",
        "raw_df = pd.read_csv(ROOT_PATH + DATA_PATH + '/Annotationen-Stufe-2.csv', index_col=0)\n",
        "# Drop rows where Textstelle is NaN\n",
        "index_names = raw_df[raw_df['Textstelle'].isnull()].index\n",
        "raw_df.drop(index_names, inplace=True)\n",
        "# setting the Stärkegrad if not present\n",
        "raw_df = set_default_staerkegrad_df(raw_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em8WSY-lJwgD",
        "outputId": "c6f1e2fd-1d04-47f0-b933-bca0ad4308dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Seite                                         Textstelle Metapher?  \\\n",
              "0      NaN   Bei Beobachtung solchen moralischen Wertes ka...  Metapher   \n",
              "2      NaN   Diese wolle die bittere Auslese, ohne die auc...  Metapher   \n",
              "3      NaN   Wenn es dem Verfasser gelungen ist, ein gesic...  Metapher   \n",
              "7      NaN   Man kann vielmehr in das Getriebe des gesells...  Metapher   \n",
              "9      NaN   Wohlfahrt hätte, wäre ein absurdum. Dies komm...  Metapher   \n",
              "...    ...                                                ...       ...   \n",
              "2690   NaN  137\\tAm einfachsten und am schnellsten wird de...  Metapher   \n",
              "2691   NaN  188\\tIndem ich meine Leser einlade, mit mir da...  Metapher   \n",
              "2692   NaN  Hat aber die Abstammungslehre recht, so muß si...  Metapher   \n",
              "2693   NaN  Lassen sich nach dem zuletztGesagten die Organ...  Metapher   \n",
              "2694   NaN  Die Amerikaner folgern, da sie alle Rohmateria...  Metapher   \n",
              "\n",
              "                                                  Fokus  \\\n",
              "0                                  das Horoskop stellen   \n",
              "2                                               bittere   \n",
              "3     ein gesichertes Fundament und die ersten Pfeil...   \n",
              "7                              Leuchte der Wissenschaft   \n",
              "9          fast die ganze Außenwelt lückenlos umspannen   \n",
              "...                                                 ...   \n",
              "2690  ['der gordische Knoten', 'dem Schwerte', 'durc...   \n",
              "2691  ['der engen Eingangspforte', 'Eintrittskarte',...   \n",
              "2692          ['keine Violine', 'keine Violine da ist']   \n",
              "2693                    ['Damm', 'durchbricht', 'Damm']   \n",
              "2694       ['einer turmhohen Mauer', 'turmhohen Mauer']   \n",
              "\n",
              "                                                 Rahmen Stärkegrad (A, B, C)  \\\n",
              "0                                          einer Nation                    B   \n",
              "2                                               Auslese                    A   \n",
              "3     die Lösung der hier zur Bearbeitung gestellten...                    A   \n",
              "7         in das Getriebe des gesellschaftlichen Lebens                    B   \n",
              "9                               des Menschen Interessen                    B   \n",
              "...                                                 ...                  ...   \n",
              "2690  ['dieser Frage', 'des \"frommen Glaubens\"', '',...                  NaN   \n",
              "2691  ['das weite Gebiet der monistischen Philosophi...                  NaN   \n",
              "2692  ['lückenlosen Übergänge', 'um sie zum Ausdruck...                  NaN   \n",
              "2693  ['naturwissenschaftlicher Forschnngsgrundsätze...                  NaN   \n",
              "2694               ['Schutzzöllen', 'von Schutzzöllen']                  NaN   \n",
              "\n",
              "                                   Begründung/Kommentar     Annotator  \\\n",
              "0     Horoskop stellen - bezogen auf Nationen ist da...             B   \n",
              "2     Unauffällig, aber doch metaphorisch: Dass eine...             B   \n",
              "3     Bruch, Fokus nicht ohne Bedeutungsverlust erse...             B   \n",
              "7     Bruch, semantische Erweiterung, nicht ersetzba...             B   \n",
              "9     Irritation, unersetzlich, Bedeutungserweiterun...             B   \n",
              "...                                                 ...           ...   \n",
              "2690                                                NaN  GoldStandard   \n",
              "2691                                                NaN  GoldStandard   \n",
              "2692                                                NaN  GoldStandard   \n",
              "2693                                                NaN  GoldStandard   \n",
              "2694                                                NaN  GoldStandard   \n",
              "\n",
              "     Unnamed: 2 Semantikerweiterung? Unersetzlich? sprachlich irregulär?  \\\n",
              "0           NaN                  NaN           NaN                   NaN   \n",
              "2           NaN                  NaN           NaN                   NaN   \n",
              "3           NaN                  NaN           NaN                   NaN   \n",
              "7           NaN                  NaN           NaN                   NaN   \n",
              "9           NaN                  NaN           NaN                   NaN   \n",
              "...         ...                  ...           ...                   ...   \n",
              "2690        NaN                  NaN           NaN                   NaN   \n",
              "2691        NaN                  NaN           NaN                   NaN   \n",
              "2692        NaN                  NaN           NaN                   NaN   \n",
              "2693        NaN                  NaN           NaN                   NaN   \n",
              "2694        NaN                  NaN           NaN                   NaN   \n",
              "\n",
              "     pointiert?                                           Filename  \\\n",
              "0           NaN                                                NaN   \n",
              "2           NaN                                                NaN   \n",
              "3           NaN                                                NaN   \n",
              "7           NaN                                                NaN   \n",
              "9           NaN                                                NaN   \n",
              "...         ...                                                ...   \n",
              "2690        NaN  ['Haeckel_Lebenswunder_Stufe2_B.xmi', 'Haeckel...   \n",
              "2691        NaN  ['Haeckel_Lebenswunder_Stufe2_B.xmi', 'Haeckel...   \n",
              "2692        NaN  ['Haecker_Stufe2_T.xmi', 'Haecker_Stufe2_P.xmi...   \n",
              "2693        NaN  ['Haecker_Stufe2_T.xmi', 'Haecker_Stufe2_T.xmi...   \n",
              "2694        NaN  ['Schalk_Stufe2_B_5.xmi', 'Schalk_Stufe2_T_5.x...   \n",
              "\n",
              "                               Synonym (aus Englischem)  \\\n",
              "0                                                   NaN   \n",
              "2                                                   NaN   \n",
              "3                                                   NaN   \n",
              "7                                                   NaN   \n",
              "9                                                   NaN   \n",
              "...                                                 ...   \n",
              "2690  137 Der einfachste und schnellste Weg, den gor...   \n",
              "2691  188 Indem ich meine Leser einlade, mit mir noc...   \n",
              "2692  Wenn aber die Abstammungstheorie richtig ist, ...   \n",
              "2693  Wenn nach Letzterem Organismen nicht nur mit R...   \n",
              "2694  Da die Amerikaner alle Rohstoffe selbst produz...   \n",
              "\n",
              "                               Synonym (aus Spanischem)  \\\n",
              "0                                                   NaN   \n",
              "2                                                   NaN   \n",
              "3                                                   NaN   \n",
              "7                                                   NaN   \n",
              "9                                                   NaN   \n",
              "...                                                 ...   \n",
              "2690  137 Der einfachste und schnellste Weg, den gor...   \n",
              "2691  188 Indem ich meine Leser einlade, mit mir noc...   \n",
              "2692  Aber wenn die Abstammungstheorie richtig ist, ...   \n",
              "2693  Wenn demnach Organismen nicht nur mit den Prod...   \n",
              "2694  Die Amerikaner kommen zu dem Schluß, daß es, d...   \n",
              "\n",
              "                             Synonym (aus Tchechischem)  \\\n",
              "0                                                   NaN   \n",
              "2                                                   NaN   \n",
              "3                                                   NaN   \n",
              "7                                                   NaN   \n",
              "9                                                   NaN   \n",
              "...                                                 ...   \n",
              "2690  137 Der einfachste und schnellste Weg, den gor...   \n",
              "2691  188 Wenn ich meine Leser einlade, mit mir das ...   \n",
              "2692  Aber wenn die Ursprungstheorie richtig ist, mu...   \n",
              "2693  Wenn nach ihm Organismen nicht nur mit Produkt...   \n",
              "2694  Die Amerikaner sind zu dem Schluss gekommen, d...   \n",
              "\n",
              "                               Synonym (aus Polnischem)  \n",
              "0                                                   NaN  \n",
              "2                                                   NaN  \n",
              "3                                                   NaN  \n",
              "7                                                   NaN  \n",
              "9                                                   NaN  \n",
              "...                                                 ...  \n",
              "2690  Der einfachste und schnellste Weg, den gordisc...  \n",
              "2691  188 Indem ich meine Leser einlade, mit mir noc...  \n",
              "2692  Aber wenn die Abstammungstheorie richtig ist, ...  \n",
              "2693  Wenn nach dieser Auffassung Organismen nicht n...  \n",
              "2694  Die Amerikaner sind zu dem Schluss gekommen, d...  \n",
              "\n",
              "[906 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ae3fc94-66ae-498e-80fa-5df0a52105ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Seite</th>\n",
              "      <th>Textstelle</th>\n",
              "      <th>Metapher?</th>\n",
              "      <th>Fokus</th>\n",
              "      <th>Rahmen</th>\n",
              "      <th>Stärkegrad (A, B, C)</th>\n",
              "      <th>Begründung/Kommentar</th>\n",
              "      <th>Annotator</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Semantikerweiterung?</th>\n",
              "      <th>Unersetzlich?</th>\n",
              "      <th>sprachlich irregulär?</th>\n",
              "      <th>pointiert?</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Synonym (aus Englischem)</th>\n",
              "      <th>Synonym (aus Spanischem)</th>\n",
              "      <th>Synonym (aus Tchechischem)</th>\n",
              "      <th>Synonym (aus Polnischem)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Bei Beobachtung solchen moralischen Wertes ka...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>das Horoskop stellen</td>\n",
              "      <td>einer Nation</td>\n",
              "      <td>B</td>\n",
              "      <td>Horoskop stellen - bezogen auf Nationen ist da...</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Diese wolle die bittere Auslese, ohne die auc...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>bittere</td>\n",
              "      <td>Auslese</td>\n",
              "      <td>A</td>\n",
              "      <td>Unauffällig, aber doch metaphorisch: Dass eine...</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Wenn es dem Verfasser gelungen ist, ein gesic...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>ein gesichertes Fundament und die ersten Pfeil...</td>\n",
              "      <td>die Lösung der hier zur Bearbeitung gestellten...</td>\n",
              "      <td>A</td>\n",
              "      <td>Bruch, Fokus nicht ohne Bedeutungsverlust erse...</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Man kann vielmehr in das Getriebe des gesells...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>Leuchte der Wissenschaft</td>\n",
              "      <td>in das Getriebe des gesellschaftlichen Lebens</td>\n",
              "      <td>B</td>\n",
              "      <td>Bruch, semantische Erweiterung, nicht ersetzba...</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Wohlfahrt hätte, wäre ein absurdum. Dies komm...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>fast die ganze Außenwelt lückenlos umspannen</td>\n",
              "      <td>des Menschen Interessen</td>\n",
              "      <td>B</td>\n",
              "      <td>Irritation, unersetzlich, Bedeutungserweiterun...</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2690</th>\n",
              "      <td>NaN</td>\n",
              "      <td>137\\tAm einfachsten und am schnellsten wird de...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>['der gordische Knoten', 'dem Schwerte', 'durc...</td>\n",
              "      <td>['dieser Frage', 'des \"frommen Glaubens\"', '',...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Haeckel_Lebenswunder_Stufe2_B.xmi', 'Haeckel...</td>\n",
              "      <td>137 Der einfachste und schnellste Weg, den gor...</td>\n",
              "      <td>137 Der einfachste und schnellste Weg, den gor...</td>\n",
              "      <td>137 Der einfachste und schnellste Weg, den gor...</td>\n",
              "      <td>Der einfachste und schnellste Weg, den gordisc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2691</th>\n",
              "      <td>NaN</td>\n",
              "      <td>188\\tIndem ich meine Leser einlade, mit mir da...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>['der engen Eingangspforte', 'Eintrittskarte',...</td>\n",
              "      <td>['das weite Gebiet der monistischen Philosophi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Haeckel_Lebenswunder_Stufe2_B.xmi', 'Haeckel...</td>\n",
              "      <td>188 Indem ich meine Leser einlade, mit mir noc...</td>\n",
              "      <td>188 Indem ich meine Leser einlade, mit mir noc...</td>\n",
              "      <td>188 Wenn ich meine Leser einlade, mit mir das ...</td>\n",
              "      <td>188 Indem ich meine Leser einlade, mit mir noc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2692</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Hat aber die Abstammungslehre recht, so muß si...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>['keine Violine', 'keine Violine da ist']</td>\n",
              "      <td>['lückenlosen Übergänge', 'um sie zum Ausdruck...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Haecker_Stufe2_T.xmi', 'Haecker_Stufe2_P.xmi...</td>\n",
              "      <td>Wenn aber die Abstammungstheorie richtig ist, ...</td>\n",
              "      <td>Aber wenn die Abstammungstheorie richtig ist, ...</td>\n",
              "      <td>Aber wenn die Ursprungstheorie richtig ist, mu...</td>\n",
              "      <td>Aber wenn die Abstammungstheorie richtig ist, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2693</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Lassen sich nach dem zuletztGesagten die Organ...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>['Damm', 'durchbricht', 'Damm']</td>\n",
              "      <td>['naturwissenschaftlicher Forschnngsgrundsätze...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Haecker_Stufe2_T.xmi', 'Haecker_Stufe2_T.xmi...</td>\n",
              "      <td>Wenn nach Letzterem Organismen nicht nur mit R...</td>\n",
              "      <td>Wenn demnach Organismen nicht nur mit den Prod...</td>\n",
              "      <td>Wenn nach ihm Organismen nicht nur mit Produkt...</td>\n",
              "      <td>Wenn nach dieser Auffassung Organismen nicht n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2694</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Die Amerikaner folgern, da sie alle Rohmateria...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>['einer turmhohen Mauer', 'turmhohen Mauer']</td>\n",
              "      <td>['Schutzzöllen', 'von Schutzzöllen']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Schalk_Stufe2_B_5.xmi', 'Schalk_Stufe2_T_5.x...</td>\n",
              "      <td>Da die Amerikaner alle Rohstoffe selbst produz...</td>\n",
              "      <td>Die Amerikaner kommen zu dem Schluß, daß es, d...</td>\n",
              "      <td>Die Amerikaner sind zu dem Schluss gekommen, d...</td>\n",
              "      <td>Die Amerikaner sind zu dem Schluss gekommen, d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>906 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ae3fc94-66ae-498e-80fa-5df0a52105ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ae3fc94-66ae-498e-80fa-5df0a52105ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ae3fc94-66ae-498e-80fa-5df0a52105ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Loading annotated data of the gold standard\n",
        "gold_standard_df = pd.read_csv(ROOT_PATH + DATA_PATH + '/goldstandard_dataframe_oversampled.csv')\n",
        "\n",
        "# Loading annotated data for non-metaphors\n",
        "no_metaphor_df = pd.read_csv(ROOT_PATH + DATA_PATH + '/NoMetaphor.csv', index_col=0)\n",
        "\n",
        "# Combine all data into one DataFrame\n",
        "raw_df = pd.concat([raw_df, gold_standard_df, no_metaphor_df], axis=0,ignore_index=True)\n",
        "\n",
        "# If the related parameter is set to true and a valid Deepl API Key is present, oversampling will be performed on the raw_df and this oversampled_data_df will be saved as .csv file\n",
        "if (oversample_dataframe and deepl_auth_key != 'DEEPL_AUTH_KEY'):\n",
        "  oversampled_data_df = oversample_dataframe(gold_standard_df)\n",
        "  oversampled_data_df.to_csv('goldstandard_dataframe_oversampled.csv', index=False)\n",
        "\n",
        "display(raw_df[raw_df['Metapher?'] == 'Metapher'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtaoWFNCq6R_"
      },
      "source": [
        "### Get data by annotator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1fIs9Rkq_MB",
        "outputId": "42b1d95c-a036-4e5c-aca5-a637e12b1084"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Seite                                         Textstelle Metapher? Fokus  \\\n",
              "0   NaN  Es scheint mir allerhöchste Zeit, an eine syst...      Nein   NaN   \n",
              "1   NaN  Es ist auch nicht möglich, dieser Subjektivitä...      Nein   NaN   \n",
              "\n",
              "  Rahmen Stärkegrad (A, B, C) Begründung/Kommentar Annotator Unnamed: 2  \\\n",
              "0    NaN                  NaN                  NaN         X        NaN   \n",
              "1    NaN                  NaN                  NaN         X        NaN   \n",
              "\n",
              "  Semantikerweiterung? Unersetzlich? sprachlich irregulär? pointiert?  \\\n",
              "0                  NaN           NaN                   NaN        NaN   \n",
              "1                  NaN           NaN                   NaN        NaN   \n",
              "\n",
              "                         Filename Synonym (aus Englischem)  \\\n",
              "0  nus5_2_Michaelis_bereinigt.txt                      NaN   \n",
              "1     nus2_2_ruppin_bereinigt.txt                      NaN   \n",
              "\n",
              "  Synonym (aus Spanischem) Synonym (aus Tchechischem) Synonym (aus Polnischem)  \n",
              "0                      NaN                        NaN                      NaN  \n",
              "1                      NaN                        NaN                      NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-560245e3-6f47-4017-944a-528b43889e4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Seite</th>\n",
              "      <th>Textstelle</th>\n",
              "      <th>Metapher?</th>\n",
              "      <th>Fokus</th>\n",
              "      <th>Rahmen</th>\n",
              "      <th>Stärkegrad (A, B, C)</th>\n",
              "      <th>Begründung/Kommentar</th>\n",
              "      <th>Annotator</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Semantikerweiterung?</th>\n",
              "      <th>Unersetzlich?</th>\n",
              "      <th>sprachlich irregulär?</th>\n",
              "      <th>pointiert?</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Synonym (aus Englischem)</th>\n",
              "      <th>Synonym (aus Spanischem)</th>\n",
              "      <th>Synonym (aus Tchechischem)</th>\n",
              "      <th>Synonym (aus Polnischem)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Es scheint mir allerhöchste Zeit, an eine syst...</td>\n",
              "      <td>Nein</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>nus5_2_Michaelis_bereinigt.txt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Es ist auch nicht möglich, dieser Subjektivitä...</td>\n",
              "      <td>Nein</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>X</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>nus2_2_ruppin_bereinigt.txt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-560245e3-6f47-4017-944a-528b43889e4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-560245e3-6f47-4017-944a-528b43889e4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-560245e3-6f47-4017-944a-528b43889e4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# annotators = ['T', 'A', 'P', 'B', 'K']\n",
        "def get_class_data_by_annotator(annotator = 'all', class_name = 'Metapher', size= 0)-> pd.DataFrame:\n",
        "  \"\"\"\n",
        "  Gets the class data by annotator\n",
        "  :param annotator: the specific annotator to data from. If 'all', data from all annotators is returned\n",
        "  :param class_name: The name of the class which should be returned\n",
        "  :param size: The size of the returned dataframe. If size=0, all data is returned\n",
        "  :return df: A dataframe of given size, containing all data of a given annotator and class\n",
        "  \"\"\"  \n",
        "  annotators = set(raw_df['Annotator'].tolist())\n",
        "  if annotator == 'all':\n",
        "    df = raw_df.loc[(raw_df['Annotator'].isin(['T', 'A', 'P', 'B', 'K', 'GoldStandard', 'X']) ) & (raw_df['Metapher?'] == class_name)]\n",
        "  elif annotator not in annotators:\n",
        "    raise Exception('The given Annotator is not found')\n",
        "  else:\n",
        "    df = raw_df.loc[(raw_df['Annotator'] == annotator) & (raw_df['Metapher?'] == class_name)]\n",
        "\n",
        "  # shuffle rows\n",
        "  df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "  if size != 0:\n",
        "    df = df.head(size)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTkYh_P2nzAo"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A simple Baseline using the DummyClassifier of sklearn. For more details see: https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html"
      ],
      "metadata": {
        "id": "ENr_Qde35du4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97ZT2LSxUG8y"
      },
      "outputs": [],
      "source": [
        "def baseline(train_texts, test_texts, train_labels, test_labels, strategy=\"most_frequent\"):\n",
        "  \"\"\"\n",
        "  Returns the Accuracy, Average Macro F1 score and individual Macro F1 score for each class for a given set of train and test data with a given \n",
        "  :param train_texts: The train set\n",
        "  :param test_texts: The test set\n",
        "  :param train_labels: The train labels\n",
        "  :param test_labels: The test labels\n",
        "  :param strategy: The strategy for the classifier (for example 'most_frequent', 'stratified')\n",
        "  :return acc: The accuracy of the baseline classifier on the given data with the given strategy\n",
        "  :return macro_f1: The average Macro F1 score of the baseline classifier on the given data with the given strategy\n",
        "  :return per_class_macro_f1: The individual class Macro F1 scores of the baseline classifier on the given data with the given strategy\n",
        "  \"\"\"  \n",
        "  dummy_clf = DummyClassifier(strategy=strategy)\n",
        "  dummy_clf.fit(train_texts, train_labels)\n",
        "  prediction = dummy_clf.predict(test_texts)\n",
        "  # calculate accuracy using sklearn's function\n",
        "  test_labels = test_labels.to_numpy(dtype=int)\n",
        "  prediction = prediction.astype(int)\n",
        "  acc = accuracy_score(test_labels, prediction)\n",
        "  macro_f1 = f1_score(test_labels, prediction, average='macro')\n",
        "  per_class_macro_f1 = f1_score(test_labels, prediction, average=None).tolist()\n",
        "\n",
        "  display(\"-----------------------------------\")\n",
        "  display(\"Baseline using strategy=\", strategy)\n",
        "  display(\"Accuracy:\", acc)\n",
        "  display(\"Macro F1:\", macro_f1)\n",
        "  display(\"Per Class Macro F1:\", per_class_macro_f1)\n",
        "  display(\"-----------------------------------\")\n",
        "\n",
        "  return acc, macro_f1, per_class_macro_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0odJrOSwImy"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLQhjhhqomfG"
      },
      "source": [
        "## Load pre-trained BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFfB99QJoq13"
      },
      "outputs": [],
      "source": [
        "def load_model_tokenizer(model_type='fine_tuned', smote=False):\n",
        "  \"\"\"\n",
        "  Returns an individual model and corresponding tokenizer \n",
        "  :param model_type: The type of model to load\n",
        "  :param smote: The test set\n",
        "  :return model: The average Macro F1 score of the baseline classifier on the given data with the given strategy\n",
        "  :return tokenizer: The individual class Macro F1 scores of the baseline classifier on the given data with the given strategy\n",
        "  \"\"\"    \n",
        "\n",
        "  if model_type == 'fine_tuned':\n",
        "    if smote>0:\n",
        "      model = BertForSequenceClassificationSMOTE.from_pretrained(ROOT_PATH + MODEL_PATH, cache_dir=None, num_labels=3)\n",
        "    else:\n",
        "      model = BertForSequenceClassification.from_pretrained(ROOT_PATH + MODEL_PATH, cache_dir=None, num_labels=3)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(ROOT_PATH + MODEL_PATH)\n",
        "  elif model_type == 'intermediate_task_vua':\n",
        "    if smote>0:\n",
        "      model = BertForSequenceClassificationSMOTE.from_pretrained(ROOT_PATH + '/intermediate-task-vua/model', num_labels=3, ignore_mismatched_sizes=True)\n",
        "    else:\n",
        "      model = BertForSequenceClassification.from_pretrained(ROOT_PATH + '/intermediate-task-vua/model', num_labels=3, ignore_mismatched_sizes=True)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(ROOT_PATH + '/intermediate-task-trofi-vua/model')\n",
        "  elif model_type == 'intermediate_task_trofi':\n",
        "    if smote>0:\n",
        "      model = BertForSequenceClassificationSMOTE.from_pretrained(ROOT_PATH + '/intermediate-task-trofi/model', num_labels=3, ignore_mismatched_sizes=True)\n",
        "    else:\n",
        "      model = BertForSequenceClassification.from_pretrained(ROOT_PATH + '/intermediate-task-trofi/model', num_labels=3, ignore_mismatched_sizes=True)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(ROOT_PATH + '/intermediate-task-trofi/model')\n",
        "  elif model_type == 'bert_base_multilingual_cased':\n",
        "    if smote:\n",
        "      model = BertForSequenceClassificationSMOTE.from_pretrained(\"bert-base-multilingual-cased\", cache_dir=None, num_labels=3)\n",
        "    else:\n",
        "      model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", cache_dir=None, num_labels=3)\n",
        "    tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "  elif model_type == 'redewiedergabe':\n",
        "    if smote:\n",
        "      model = BertForSequenceClassificationSMOTE.from_pretrained(\"redewiedergabe/bert-base-historical-german-rw-cased\", cache_dir=None, num_labels=3)\n",
        "    else:\n",
        "      model = BertForSequenceClassification.from_pretrained(\"redewiedergabe/bert-base-historical-german-rw-cased\", cache_dir=None, num_labels=3)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"redewiedergabe/bert-base-historical-german-rw-cased\")\n",
        "  return model, tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6XjS-g_wT3M"
      },
      "source": [
        "## Dataset Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iul0k2IGrY3D"
      },
      "outputs": [],
      "source": [
        "class MetaphorDataset(torch.utils.data.Dataset):\n",
        "  \"\"\"\n",
        "  The dataset class for metaphors\n",
        "  \"\"\"\n",
        "    def __init__(self, encodings, labels):\n",
        "    \"\"\"\n",
        "    Initializes the dataset\n",
        "    :param encodings: The type of model to load\n",
        "    :param labels: Boolean value to toggle SMOTE\n",
        "    \"\"\"    \n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "    \"\"\"\n",
        "    Returns an individual item by id\n",
        "    :param idx: The id of the item to return\n",
        "    :return item: The chosen item\n",
        "    \"\"\"    \n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "    \"\"\"\n",
        "    Helper to return the size of the dataset\n",
        "    :return lenght: the size of the dataset\n",
        "    \"\"\"    \n",
        "        return len(self.labels)\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    \"\"\"\n",
        "    Computes accuracy, macro_f1 score and individual macro f1 per class for a given prediction\n",
        "    :param pred: The prediction\n",
        "    :return dict: A dictionary containing accuracy, macro_f1 score and individual macro f1 per class\n",
        "    \"\"\"    \n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    # calculate accuracy using sklearn's function\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    macro_f1 = f1_score(labels, preds, average='macro')\n",
        "    per_class_macro_f1 = f1_score(labels, preds, average=None).tolist()\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'macro_f1': macro_f1,\n",
        "        'per_class_macro_f1': per_class_macro_f1,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLiqFziqwZ9R"
      },
      "source": [
        "## BERT Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAQpwma61OeZ"
      },
      "outputs": [],
      "source": [
        "def save_results(path, results, annotator):\n",
        "  \"\"\"\n",
        "  Saves the results of a training to a given path\n",
        "  :param path: The path to save to\n",
        "  :param results: The results to save\n",
        "  :param annotator: The annotator of this particular result\n",
        "  \"\"\"    \n",
        "  print(\"Saving results to\", path)\n",
        "  with open(path + '/results_'+annotator+'.csv', 'w') as csv_file:  \n",
        "    writer = csv.writer(csv_file)\n",
        "    for key, value in results.items():\n",
        "       writer.writerow([key, value])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yl4IySdV9kg"
      },
      "outputs": [],
      "source": [
        "def get_numerical_labels(df):  \n",
        "  \"\"\"\n",
        "  Returns the labels as numerical values: '0' for Non-Metaphors, '1' for Metaphor candidates and '2' for Metaphors\n",
        "  :param df: The dataframe to change\n",
        "  :return df: The changed dataframe, containing labels as numerical values\n",
        "  \"\"\" \n",
        "  df.loc[df['Metapher?'] == 'Nein', 'Metapher?'] = 0\n",
        "  df.loc[df['Metapher?'] == 'Metaphernkandidat', 'Metapher?'] = 1\n",
        "  df.loc[df['Metapher?'] == 'Unklar', 'Metapher?'] = 1\n",
        "  df.loc[df['Metapher?'] == 'Grenzfall', 'Metapher?'] = 1\n",
        "  df.loc[df['Metapher?'] == 'Metapher', 'Metapher?'] = 2\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao1URiMmI_41"
      },
      "outputs": [],
      "source": [
        " def get_oversamples(entry):\n",
        "  \"\"\"\n",
        "  Returns the oversampling entries corresponding to a specific entry\n",
        "  :param entry: The entry to get the oversampling data to\n",
        "  :return oversamples: The oversampling data to the given entry\n",
        "  \"\"\" \n",
        "  oversamples = pd.DataFrame()\n",
        "  textstelle = entry['Textstelle']\n",
        "  # getting oversampling data from gold standard\n",
        "  gold_standard_entry = get_numerical_labels(gold_standard_df[gold_standard_df['Textstelle']==textstelle])\n",
        "  for language in [\"Synonym (aus Englischem)\", \"Synonym (aus Spanischem)\", \"Synonym (aus Tchechischem)\", \"Synonym (aus Polnischem)\"]:\n",
        "    oversamples= oversamples.append(gold_standard_entry)\n",
        "    oversamples.iloc[-1]['Textstelle'] = oversamples.iloc[-1][language]\n",
        "  return oversamples\n",
        "\n",
        "def generate_oversampled_data(df, size):\n",
        "  \"\"\"\n",
        "  Generates oversampled data to given data with a specific size by randomly selecting from all oversampling data\n",
        "  :param df: The data for which oversampling data should be generated\n",
        "  :param size: The size of the generated data\n",
        "  :return new_samples: The oversampling data to the given data with given size\n",
        "  \"\"\"   \n",
        "  new_samples = pd.DataFrame()\n",
        "  for index, row in df.iterrows():\n",
        "    new_samples= new_samples.append(get_oversamples(row))\n",
        "  return new_samples.sample(size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TqdzN6uZbb7"
      },
      "outputs": [],
      "source": [
        " def df_statistics(df):\n",
        "    \"\"\"\n",
        "    Generates a statistic of a given dataframe\n",
        "    :param df: The data for which a statistic should be generated\n",
        "    :return statistic: The statistic of the given dataframe\n",
        "    \"\"\"   \n",
        "    return \"non-metaphors: {} ({:.0%}), metaphor candidates: {} ({:.0%}), metaphors: {} ({:.0%})\".format(df['Metapher?'].value_counts()[0],df['Metapher?'].value_counts()[0]/df['Metapher?'].value_counts().sum(),df['Metapher?'].value_counts()[1],df['Metapher?'].value_counts()[1]/df['Metapher?'].value_counts().sum(),df['Metapher?'].value_counts()[2],df['Metapher?'].value_counts()[2]/df['Metapher?'].value_counts().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_ucbKGUwgix"
      },
      "source": [
        "## BertForSequenceClassification with Synthetic Minority Oversampling Technique (SMOTE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsn__m_POwDJ"
      },
      "outputs": [],
      "source": [
        "class BertForSequenceClassificationSMOTE(BertPreTrainedModel):\n",
        "    \"\"\"\n",
        "    The BERT model class using SMOTE \n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        \"\"\"\n",
        "        Initializes the Model\n",
        "        :param config: The configuration for the BERT model\n",
        "        \"\"\"   \n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.config = config\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        classifier_dropout = (\n",
        "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
        "        )\n",
        "        self.dropout = nn.Dropout(classifier_dropout)\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "        # the individual points which are used for SMOTE and collected in the first epoch\n",
        "        self.points = []\n",
        "        # counts the amount of SMOTE samples created\n",
        "        self.smote_counter = 0\n",
        "        # The number of original samples in the minority class\n",
        "        self.minority_class = 0\n",
        "        # The factor of how many SMOTE samples should be produced per original sample\n",
        "        self.smote_factor = 0\n",
        "        # define k for k nearest neigbors\n",
        "        self.smote_k = 10\n",
        "        self.initialization = True\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
        "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
        "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "\n",
        "        if self.initialization:\n",
        "          for label, output in zip(labels, pooled_output):\n",
        "            if label == 2:\n",
        "              self.points.append(output.detach())\n",
        "\n",
        "        if labels is not None:\n",
        "            if self.config.problem_type is None:\n",
        "                if self.num_labels == 1:\n",
        "                    self.config.problem_type = \"regression\"\n",
        "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
        "                    self.config.problem_type = \"single_label_classification\"\n",
        "                else:\n",
        "                    self.config.problem_type = \"multi_label_classification\"\n",
        "            \n",
        "            if self.training and not self.initialization:\n",
        "              SMOTE_output = pooled_output\n",
        "              SMOTE_labels = labels\n",
        "              for label, output in zip(labels, pooled_output):\n",
        "                if self.initialization and label == 2:\n",
        "                  self.points.append(output.detach())\n",
        "                \n",
        "                # if training sample is in class 2 (i.e. metaphor)\n",
        "                elif label == 2:\n",
        "                  # get distances to all other points\n",
        "                  distances = list()\n",
        "                  for point in self.points:\n",
        "                      current_distance = torch.dist(output, point)\n",
        "                      if current_distance != 0:\n",
        "                        distances.append((point,current_distance))\n",
        "                  distances.sort(key=lambda tuple: tuple[1])\n",
        "\n",
        "                  for i in range(self.smote_factor):\n",
        "                    # chose a neighboring point\n",
        "                    chosen_neighbor = distances[random.randint(0,self.smote_k)][0]\n",
        "\n",
        "                    rand = torch.Tensor(output.shape)\n",
        "                    rand = rand.cuda()\n",
        "                    rand.random_(0, 1)\n",
        "                    # create a random synthetic datapoint between the current point and the chosen neighbor\n",
        "                    synthetic_datapoint = torch.add(output,\n",
        "                                                    torch.mul(rand, torch.add(chosen_neighbor, torch.neg(output))))\n",
        "                    \n",
        "                    # add synthetic point to train_set\n",
        "                    SMOTE_output = torch.cat((SMOTE_output, synthetic_datapoint.view(1, -1)), 0)\n",
        "                    \n",
        "                    SMOTE_labels = torch.cat((SMOTE_labels, torch.tensor([[2]], dtype=torch.long).cuda()))\n",
        "\n",
        "                    self.smote_counter += 1\n",
        "\n",
        "              pooled_output = self.dropout(SMOTE_output)\n",
        "              labels = SMOTE_labels\n",
        "            else:\n",
        "              pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "            logits = self.classifier(pooled_output)\n",
        "\n",
        "            if self.config.problem_type == \"regression\":\n",
        "                loss_fct = MSELoss()\n",
        "                if self.num_labels == 1:\n",
        "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
        "                else:\n",
        "                    loss = loss_fct(logits, labels)\n",
        "            elif self.config.problem_type == \"single_label_classification\":\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "            elif self.config.problem_type == \"multi_label_classification\":\n",
        "                loss_fct = BCEWithLogitsLoss()\n",
        "                loss = loss_fct(logits, labels)\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[2:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        if self.initialization and len(self.points) >= self.minority_class:\n",
        "          # after initializing the SMOTE embedding space, stop initialization\n",
        "          self.initialization = False\n",
        "          print(\"SMOTE embedding space initialized.\")\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OThP_jFNbZi1"
      },
      "outputs": [],
      "source": [
        "def get_smote_points(model, minority_class, train_dataset, test_dataset):\n",
        "  \"\"\"\n",
        "  Initializes the embedding space for the k-nearest neighbor algorithm use by SMOTE\n",
        "  Due to Google Colab limitations, this is implemented via an evaluation\n",
        "  :param model: The model to initialize\n",
        "  :param minority_class: The minority to oversample via SMOTE\n",
        "  :param train_dataset: The train dataset\n",
        "  :param test_dataset: The test dataset\n",
        "  :return model.points: The initialized data points\n",
        "  \"\"\"   \n",
        "  print(\"**** Saving all points in train set for SMOTE initialization *****\")\n",
        "  model.minority_class=minority_class\n",
        "\n",
        "  training_args = TrainingArguments(\n",
        "      output_dir='./results',          # output directory\n",
        "      num_train_epochs=1,              # total number of training epochs\n",
        "      per_device_train_batch_size=8,  # batch size per device during training\n",
        "      per_device_eval_batch_size=20,   # batch size for evaluation\n",
        "      warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "      weight_decay=0.01,               # strength of weight decay\n",
        "      logging_dir='./logs',            # directory for storing logs\n",
        "      load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
        "      # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
        "      save_total_limit=1,\n",
        "      save_strategy=\"epoch\",\n",
        "      logging_strategy=\"epoch\",\n",
        "      evaluation_strategy=\"epoch\",     # evaluate each `logging_steps`\n",
        "      metric_for_best_model=\"macro_f1\",\n",
        "  )\n",
        "\n",
        "  trainer = Trainer(\n",
        "      model=model,                         # the instantiated Transformers model to be trained\n",
        "      args=training_args,                  # training arguments, defined above\n",
        "      train_dataset=train_dataset,         # training dataset\n",
        "      eval_dataset=test_dataset,          # evaluation dataset\n",
        "      compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        "  )\n",
        "\n",
        "  trainer.evaluate(train_dataset)\n",
        "  model.initialization = False\n",
        "\n",
        "  return model.points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67XeOajR4aK3"
      },
      "source": [
        "##Training Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0GGQaUzq41W"
      },
      "outputs": [],
      "source": [
        "# setting the maximum sentence length\n",
        "max_length = 512\n",
        "# setting the default stärkegrad of the raw data\n",
        "raw_df = set_default_staerkegrad_df(raw_df)\n",
        "\n",
        "def train(annotator, model_type, epochs=3, folds=10, oversampling=True, smote=0, path='/'):\n",
        "  \"\"\"\n",
        "  Training a given model with k-fold cross-validation and various oversampling strategies\n",
        "  The resulting metrics are saved as CSV to a given path\n",
        "  :param annotator: The annotator on whose data to train\n",
        "  :param model_type: The type of model to use\n",
        "  :param epochs: The amount of epochs to train\n",
        "  :param folds: The amount of folds to use for k-fold cross validation\n",
        "  :param oversampling: Boolean to set true if oversampling should be used\n",
        "  :param smote: K value for smote. If set to 0, smote is deactivated\n",
        "  :param path: The path to save the results to\n",
        "  :return evaluation_results: The results of the evaluation of the trained model\n",
        "  \"\"\"     \n",
        "  print(\"Training with data from annotator\", annotator)\n",
        "  metaphor_candidates = get_class_data_by_annotator(annotator, class_name='Metaphernkandidat')\n",
        "  metaphors = get_class_data_by_annotator(annotator, class_name='Metapher')\n",
        "  # Using only the same amount of non-metaphors as metaphor candidates\n",
        "  not_metaphors = get_class_data_by_annotator(class_name='Nein', size=len(metaphor_candidates))\n",
        "\n",
        "  df = pd.concat([metaphors, metaphor_candidates, not_metaphors])\n",
        "  # Shuffle the rows  \n",
        "  df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "  # Data Statistics\n",
        "  samples = len(metaphor_candidates)+len(metaphors)+len(not_metaphors)\n",
        "  print(\"Number of individual classes in data:\", df_statistics(df))\n",
        "\n",
        "  # changing the labels to numerical values\n",
        "  df = get_numerical_labels(df)\n",
        "\n",
        "  baseline_accuracy = []\n",
        "  baseline_macro_f1 = []\n",
        "  baseline_per_class_macro_f1 = []\n",
        "\n",
        "  evaluation_accuracy = []\n",
        "  evaluation_macro_f1 = []\n",
        "  evaluation_per_class_macro_f1 = []\n",
        "\n",
        "\n",
        "  # K-Fold Cross Validation\n",
        "  kf = StratifiedKFold(n_splits=folds, shuffle=False)\n",
        "  i = 0\n",
        "  for train_index, test_index in kf.split(df['Textstelle'], df['Metapher?'].to_list()):\n",
        "    \n",
        "    model, tokenizer = load_model_tokenizer(model_type=model_type, smote=smote)\n",
        "    i += 1\n",
        "    display(\"-----------------------------------\")\n",
        "    print(\"Annotator\", annotator, \"| Fold #\", i)\n",
        "\n",
        "    train_samples = df.iloc[train_index.tolist()]\n",
        "    test_samples = df.iloc[test_index.tolist()]\n",
        "\n",
        "    train_metaphors = train_samples[train_samples[\"Metapher?\"] == 2]\n",
        "    test_metaphors = test_samples[test_samples[\"Metapher?\"] == 2]\n",
        "\n",
        "    #print(\"Number of individual classes in train:\", df_statistics(train_samples))\n",
        "    #print(\"Number of individual classes in test:\", df_statistics(test_samples))\n",
        "\n",
        "    if oversampling:\n",
        "      # add oversampled metaphors\n",
        "      oversampled__train_samples = generate_oversampled_data(df=train_metaphors, size=(train_samples['Metapher?'].value_counts()[0]-train_samples['Metapher?'].value_counts()[2]))\n",
        "\n",
        "      train_samples = pd.concat([train_samples, oversampled__train_samples]) \n",
        "\n",
        "    #print(\"Number of individual classes in train (after oversampling):\", df_statistics(train_samples))\n",
        "    #print(\"Number of individual classes in test (after oversampling):\", df_statistics(test_samples))\n",
        "\n",
        "\n",
        "    train_texts = train_samples['Textstelle']\n",
        "    test_texts = test_samples['Textstelle']\n",
        "    train_labels = train_samples['Metapher?']\n",
        "    test_labels = test_samples['Metapher?']\n",
        "\n",
        "    # Baseline\n",
        "    b_acc, b_macro_f1, b_per_class_macro_f1 = baseline(train_texts, test_texts, train_labels, test_labels, strategy=\"stratified\") # use 'most_frequent' 'stratified' or 'uniform'\n",
        "\n",
        "    baseline_accuracy.append(b_acc)\n",
        "    baseline_macro_f1.append(b_macro_f1)\n",
        "    baseline_per_class_macro_f1.append(b_per_class_macro_f1)\n",
        "    \n",
        "    train_encodings = tokenizer(train_texts.to_list(), truncation=True, padding=True, max_length=max_length)\n",
        "    test_encodings = tokenizer(test_texts.to_list(), truncation=True, padding=True, max_length=max_length)\n",
        "\n",
        "\n",
        "    # convert our tokenized data into a torch Dataset\n",
        "    train_dataset = MetaphorDataset(train_encodings, train_labels.tolist())\n",
        "    test_dataset = MetaphorDataset(test_encodings, test_labels.tolist())\n",
        "\n",
        "    if smote>0:\n",
        "      get_smote_points(model, train_samples['Metapher?'].value_counts()[2], train_dataset, test_dataset)\n",
        "      model.smote_factor = int(train_samples['Metapher?'].value_counts()[0]/train_samples['Metapher?'].value_counts()[2])-1\n",
        "      model.smote_k = smote\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',          # output directory\n",
        "        num_train_epochs=epochs,              # total number of training epochs\n",
        "        per_device_train_batch_size=8,  # batch size per device during training\n",
        "        per_device_eval_batch_size=20,   # batch size for evaluation\n",
        "        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "        weight_decay=0.01,               # strength of weight decay\n",
        "        logging_dir='./logs',            # directory for storing logs\n",
        "        load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
        "        # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
        "        save_total_limit=1,\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_strategy=\"epoch\",\n",
        "        evaluation_strategy=\"epoch\",     # evaluate each `logging_steps`\n",
        "        metric_for_best_model=\"macro_f1\",\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,                         # the instantiated Transformers model to be trained\n",
        "        args=training_args,                  # training arguments, defined above\n",
        "        train_dataset=train_dataset,         # training dataset\n",
        "        eval_dataset=test_dataset,          # evaluation dataset\n",
        "        compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    #print(\"SMOTE created\", model.smote_counter, \"synthetic data points\")\n",
        "\n",
        "    evaluation = trainer.evaluate()\n",
        "\n",
        "    evaluation_accuracy.append(evaluation['eval_accuracy'])\n",
        "    evaluation_macro_f1.append(evaluation['eval_macro_f1'])\n",
        "    evaluation_per_class_macro_f1.append(evaluation['eval_per_class_macro_f1'])\n",
        "  \n",
        "  evaluation_results = {\n",
        "    \"baseline_accuracy\": baseline_accuracy,\n",
        "    \"baseline_macro_f1\": baseline_macro_f1,\n",
        "    \"baseline_per_class_macro_f1\": baseline_per_class_macro_f1,\n",
        "    \"evaluation_accuracy\": evaluation_accuracy,\n",
        "    \"evaluation_macro_f1\": evaluation_macro_f1,\n",
        "    \"evaluation_per_class_macro_f1\": evaluation_per_class_macro_f1\n",
        "  }\n",
        "\n",
        "  try:\n",
        "    save_results(path,evaluation_results, annotator)\n",
        "  except:\n",
        "    print(\"There seems to be a problem with Google Drive. The CSV could not be saved. Results are only stored locally in results[annotator].\")\n",
        "  return evaluation_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32NV8Mi3oFlJ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "_E-7RB5RvVCU",
        "outputId": "2a82c15c-a237-4ed2-e9b5-ba5a0972f039"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-50d9f65129bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0msave_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRUN_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mANNOTATORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFOLDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOVERSAMPLING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOMMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GoldStandard'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFOLDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversampling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOVERSAMPLING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSMOTE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRUN_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0mcurrent_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mfoldernames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ],
      "source": [
        "#########################\n",
        "# Parameters for Training\n",
        "ANNOTATORS = ['T', 'A', 'P', 'B', 'K', 'GoldStandard'] # specify the annotators on which to train. Possible annotators = ['T', 'A', 'P', 'B', 'K', 'GoldStandard']\n",
        "EPOCHS=3\n",
        "FOLDS=10\n",
        "OVERSAMPLING = False\n",
        "SMOTE = 0 #This defines the factor k for k-nearest-neighbors used by SMOTE. SMOTE is off if set to 0.\n",
        "COMMENT='Unbalanced for all annotators.'\n",
        "#########################\n",
        "transformers.logging.set_verbosity_error()\n",
        "\n",
        "current_results = {}\n",
        "SAVE_RESULTS = True\n",
        "foldernames = [] \n",
        "\n",
        "models = ['redewiedergabe', 'fine_tuned', 'bert_base_multilingual_cased', 'intermediate_task_trofi', 'intermediate_task_vua'] # possible model_types are 'redewiedergabe', 'bert_base_multilingual_cased', 'fine_tuned', 'intermediate_task_trofi' and 'intermediate_task_vua'\n",
        "for model in models: \n",
        "  folder_name = datetime.today().strftime('%Y-%m-%d-%H:%M:%S') + \" | \" + model + \" | EPOCHS \"+ str(EPOCHS)+ \" | FOLDS \"+ str(FOLDS)+ ((\" | SMOTE (K=\"+str(SMOTE)+\")\") if SMOTE>0 else \"\") + ((\" | OVERSAMPLING\") if OVERSAMPLING>0 else \"\")\n",
        "  RUN_PATH = ROOT_PATH + RESULTS_PATH + '/runs/' + folder_name\n",
        "\n",
        "  if SAVE_RESULTS:\n",
        "    print(RUN_PATH)\n",
        "    !mkdir \"$RUN_PATH\"\n",
        "    save_settings(RUN_PATH, ANNOTATORS, EPOCHS, FOLDS, model, OVERSAMPLING, SMOTE, COMMENT)\n",
        "    foldernames.append(folder_name)\n",
        "\n",
        "  for annotator in ANNOTATORS: \n",
        "    result = train(annotator, model, epochs=EPOCHS, folds=FOLDS, oversampling=OVERSAMPLING, smote=SMOTE, path=RUN_PATH) \n",
        "    current_results[annotator] = result\n",
        "    foldernames.append(folder_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg2WxYVzoOED"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0FkSzFbQlmL"
      },
      "outputs": [],
      "source": [
        "def open_csv(path):\n",
        "  \"\"\"\n",
        "  Loads all CSV data for plotting\n",
        "  :param path: The path to load from\n",
        "  :return df: The loaded data as a dataframe\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(path, names=['measure', 'results'], header=None)\n",
        "  annotator = path[-5]\n",
        "  \n",
        "  df['results'] = df['results'].apply(lambda x: np.array(json.loads(x)))\n",
        "  df['annotator'] = annotator\n",
        "  return df\n",
        "\n",
        "# Plotting with multiple annotators\n",
        "def open_csv_annotators(path, annotator):\n",
        "  \"\"\"\n",
        "  Loads all CSV data for plotting for individual annotators\n",
        "  :param path: The path to load from\n",
        "  :return df: The loaded data as a dataframe\n",
        "  \"\"\"\n",
        "  print(path)\n",
        "  try:\n",
        "    df = pd.read_csv(path, names=['measure', 'results'], header=None)\n",
        "    df['results'] = df['results'].apply(lambda x: np.fromstring(x[1:-1], sep=', '))\n",
        "    df['annotator'] = annotator\n",
        "    annotator_names.append(annotator)\n",
        "  except:\n",
        "    df = pd.DataFrame()\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gold Standard"
      ],
      "metadata": {
        "id": "BwRRKVTQrKYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All results of our runs can be found in the following folders"
      ],
      "metadata": {
        "id": "UQxGBINFOvQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unbalanced data \n",
        "unbalanced = [\"2022-03-18-14:22:25 | redewiedergabe | EPOCHS 3 | FOLDS 10\", \n",
        "         \"2022-03-18-15:39:18 | fine_tuned | EPOCHS 3 | FOLDS 10\", \n",
        "        \"2022-03-18-19:58:33 | bert_base_multilingual_cased | EPOCHS 3 | FOLDS 10\",\n",
        "         \"2022-03-18-16:56:29 | intermediate_task_trofi | EPOCHS 3 | FOLDS 10\",\n",
        "         \"2022-03-18-22:39:23 | intermediate_task_vua | EPOCHS 3 | FOLDS 10\"]\n",
        "\n",
        "# Oversampling data\n",
        "oversampling = [\"2022-03-18-15:45:00 | redewiedergabe | EPOCHS 3 | FOLDS 10 | OVERSAMPLING\", \n",
        "         \"2022-03-18-17:23:14 | fine_tuned | EPOCHS 3 | FOLDS 10 | OVERSAMPLING\", \n",
        "         \"2022-03-19-16:33:56 | bert_base_multilingual_cased | EPOCHS 3 | FOLDS 10 | OVERSAMPLING\",\n",
        "         \"2022-03-18-19:04:18 | intermediate_task_trofi | EPOCHS 3 | FOLDS 10 | OVERSAMPLING\",\n",
        "         \"2022-03-18-21:23:18 | intermediate_task_vua | EPOCHS 3 | FOLDS 10 | OVERSAMPLING\"]\n",
        "\n",
        "# SMOTE data \n",
        "smote = [\"2022-03-18-15:27:18 | redewiedergabe | EPOCHS 3 | FOLDS 10 | SMOTE (K=10)\", \n",
        "         \"2022-03-18-16:54:45 | fine_tuned | EPOCHS 3 | FOLDS 10 | SMOTE (K=10)\", \n",
        "         \"2022-03-19-14:49:00 | bert_base_multilingual_cased | EPOCHS 3 | FOLDS 10 | SMOTE (K=10)\",\n",
        "         \"2022-03-19-09:03:31 | intermediate_task_trofi | EPOCHS 3 | FOLDS 10 | SMOTE (K=10)\", \n",
        "         \"2022-03-19-10:53:52 | intermediate_task_vua | EPOCHS 3 | FOLDS 10 | SMOTE (K=10)\"]"
      ],
      "metadata": {
        "id": "DhFaKnQ_OsaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxlb6OXcvc5m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "030d4fd0-5530-46c5-ae54-db3a517a59c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/DLDH/results/plots/results-oversampling.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 936x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Filename to save the plot to\n",
        "filename = \"results-oversampling\"\n",
        "\n",
        "files = oversampling # insert foldernames of previous runs here if needed for plotting\n",
        "\n",
        "files = [ROOT_PATH + RESULTS_PATH + \"/runs/\" +  x + \"/results_GoldStandard.csv\" for x in files]\n",
        "dfs = [open_csv(filename) for filename in files]\n",
        "\n",
        "redewiedergabe = open_csv(files[0])\n",
        "fine_tuned = open_csv(files[1])\n",
        "bert_base_multilingual = open_csv(files[2])\n",
        "intermediate_task = open_csv(files[3])\n",
        "intermediate_task_vua = open_csv(files[4])\n",
        "\n",
        "models = {'DummyClassifier\\n$\\it{\\'stratified\\'}$': (redewiedergabe[(redewiedergabe.measure == 'baseline_accuracy')].results.iloc[0], redewiedergabe[(redewiedergabe.measure == 'baseline_macro_f1')].results.iloc[0]), \n",
        "          'redewiedergabe': (redewiedergabe[(redewiedergabe.measure == 'evaluation_accuracy')].results.iloc[0], redewiedergabe[(redewiedergabe.measure == 'evaluation_macro_f1')].results.iloc[0]),\n",
        "          'Pretrained':(fine_tuned[(fine_tuned.measure == 'evaluation_accuracy')].results.iloc[0], fine_tuned[(fine_tuned.measure == 'evaluation_macro_f1')].results.iloc[0]),\n",
        "          'bert-base\\nmultilingual-cased':(bert_base_multilingual[(bert_base_multilingual.measure == 'evaluation_accuracy')].results.iloc[0], bert_base_multilingual[(bert_base_multilingual.measure == 'evaluation_macro_f1')].results.iloc[0]),\n",
        "          'Intermediate-Task\\n($\\it{TroFi}$)': (intermediate_task[(intermediate_task.measure == 'evaluation_accuracy')].results.iloc[0], intermediate_task[(intermediate_task.measure == 'evaluation_macro_f1')].results.iloc[0]),\n",
        "          'Intermediate-Task\\n($\\it{VUA}$)': (intermediate_task_vua[(intermediate_task_vua.measure == 'evaluation_accuracy')].results.iloc[0], intermediate_task_vua[(intermediate_task_vua.measure == 'evaluation_macro_f1')].results.iloc[0])\n",
        "          } \n",
        "\n",
        "\n",
        "plt.figure(figsize=(13,5))\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Macro-F1\")\n",
        "mean = []\n",
        "std = []\n",
        "mean_macro = []\n",
        "std_macro = []\n",
        "model_names = []\n",
        "\n",
        "\n",
        "for name, data in models.items():\n",
        "  accuracy = data[0]\n",
        "  mean.append(np.mean(accuracy))\n",
        "  std.append(np.std(accuracy))\n",
        "  macro_f1 = data[1]\n",
        "  mean_macro.append(np.mean(macro_f1))\n",
        "  std_macro.append(np.std(macro_f1))\n",
        "  model_names.append(name)\n",
        "\n",
        "\n",
        "plt.errorbar(model_names, mean_macro, yerr=std_macro, capsize=10, ls='none', label='Standard Deviation')\n",
        "plt.scatter(model_names, mean_macro, c='black', zorder=2, label='Mean')\n",
        "for i, v in enumerate(mean_macro):\n",
        "  plt.annotate(round(v, 2), (i, v),xytext=(10, 0), textcoords='offset points')\n",
        "filepath = ROOT_PATH + RESULTS_PATH + '/plots/' + filename + '.pdf'\n",
        "print(filepath)\n",
        "plt.title(\"\")\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig(filepath, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Individual classes"
      ],
      "metadata": {
        "id": "S_hm5i3e3RtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting for individual classes\n",
        "# Filename to save the plot to\n",
        "filename = \"results-unbalanced-individual\"\n",
        "\n",
        "files = unbalanced # insert foldernames of previous runs here if needed for plotting\n",
        "\n",
        "files = [ROOT_PATH + RESULTS_PATH + \"/runs/\" +  x + \"/results_GoldStandard.csv\" for x in files]\n",
        "\n",
        "redewiedergabe = open_csv(files[0])\n",
        "fine_tuned = open_csv(files[1])\n",
        "bert_base_multilingual = open_csv(files[2])\n",
        "intermediate_task_trofi = open_csv(files[3])\n",
        "intermediate_task_vua = open_csv(files[4])\n",
        "\n",
        "models = {'DummyClassifier\\n$\\it{\\'stratified\\'}$': (fine_tuned[(fine_tuned.measure == 'baseline_macro_f1')].results.iloc[0], fine_tuned[(fine_tuned.measure == 'baseline_per_class_macro_f1')].results.iloc[0]), \n",
        "          'redewiedergabe': (redewiedergabe[(redewiedergabe.measure == 'evaluation_macro_f1')].results.iloc[0], redewiedergabe[(redewiedergabe.measure == 'evaluation_per_class_macro_f1')].results.iloc[0]),\n",
        "          'Pretrained': (fine_tuned[(fine_tuned.measure == 'evaluation_macro_f1')].results.iloc[0],fine_tuned[(fine_tuned.measure == 'evaluation_per_class_macro_f1')].results.iloc[0]),\n",
        "          'bert-base\\nmultilingual-cased': (bert_base_multilingual[(bert_base_multilingual.measure == 'evaluation_macro_f1')].results.iloc[0],bert_base_multilingual[(bert_base_multilingual.measure == 'evaluation_per_class_macro_f1')].results.iloc[0]),\n",
        "          'Intermediate-Task\\n($\\it{TroFi}$)': (intermediate_task_trofi[(intermediate_task_trofi.measure == 'evaluation_macro_f1')].results.iloc[0],intermediate_task_trofi[(intermediate_task_trofi.measure == 'evaluation_per_class_macro_f1')].results.iloc[0]),\n",
        "          'Intermediate-Task\\n($\\it{VUA}$)': (intermediate_task_vua[(intermediate_task_vua.measure == 'evaluation_macro_f1')].results.iloc[0],intermediate_task_vua[(intermediate_task_vua.measure == 'evaluation_per_class_macro_f1')].results.iloc[0])\n",
        "          } \n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.xlabel(\"Model\", fontweight='bold')\n",
        "plt.ylabel(\"Macro-F1\", fontweight='bold')\n",
        "mean_macro = []\n",
        "std_macro = []\n",
        "mean_per_class_macro = []\n",
        "std_per_class_macro = []\n",
        "model_names = []\n",
        "\n",
        "stride = 4\n",
        "\n",
        "for name, data in models.items():\n",
        "  macro_f1 = data[0]\n",
        "  mean_macro.append(np.mean(macro_f1))\n",
        "  std_macro.append(np.std(macro_f1))\n",
        "  per_class_macro_f1 = data[1]\n",
        "  per_class_macro_f1_mean = np.mean(per_class_macro_f1, axis=0).tolist()\n",
        "  mean_per_class_macro.extend(per_class_macro_f1_mean)\n",
        "  mean_per_class_macro.append(np.nan)\n",
        "  std_per_class_macro.extend(np.std(per_class_macro_f1, axis=0).tolist())\n",
        "  std_per_class_macro.append(np.nan)\n",
        "  model_names.append(name)\n",
        "\n",
        "x_ticks = np.arange(len(mean_per_class_macro))\n",
        "classes = ['non-metaphors', 'metaphor candidates', 'metaphors']\n",
        "colors = ['red', 'blue', 'green']\n",
        "\n",
        "latex = \"Oversampled \"\n",
        "\n",
        "for mean, std in zip(mean_macro, std_macro):\n",
        "  latex += \"& {:.2f}\".format(round(mean, 2)) + \" ({:.2f}) \".format(round(std, 2)) \n",
        "\n",
        "latex += \"\\\\\\\\ dataset\"\n",
        "\n",
        "for i in range(0,len(mean_per_class_macro),stride):\n",
        "  latex+= \" & \\\\small [{:.1f}, {:.1f}, {:.1f}]\".format(round(mean_per_class_macro[i], 1),round(mean_per_class_macro[i+1], 1),round(mean_per_class_macro[i+2], 1))\n",
        "\n",
        "print(latex)\n",
        "\n",
        "for i in range(3):\n",
        "  x = [x_ticks[j] for j in range(i, len(x_ticks), stride)]\n",
        "  m = [mean_per_class_macro[j] for j in range(i, len(x_ticks), stride)]\n",
        "  s = [std_per_class_macro[j] for j in range(i, len(x_ticks), stride)]\n",
        "  plt.errorbar(x, m, yerr=s, capsize=10, ls='none', label=classes[i], c = colors[i])\n",
        "\n",
        "\n",
        "plt.scatter(x_ticks, mean_per_class_macro, c='black', zorder=2, label='Mean')\n",
        "\n",
        "for i, v in enumerate(mean_per_class_macro):\n",
        "  plt.annotate(round(v, 2), (i, v),xytext=(10, 0), textcoords='offset points')\n",
        "\n",
        "# custom legend\n",
        "plt.plot([], [], ' ', label=\"$\\it{Standard\\ deviation\\ of}$\")\n",
        "#get handles and labels\n",
        "handles, labels = plt.gca().get_legend_handles_labels()\n",
        "#specify order of items in legend\n",
        "order = [1,0,2,3,4]\n",
        "#add legend to plot\n",
        "plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order], loc='upper left') \n",
        "\n",
        "model_ticks = [x*stride +1 for x in range(len(model_names))]\n",
        "plt.xticks(model_ticks)\n",
        "plt.axes().set_xticklabels(model_names)\n",
        "filepath = ROOT_PATH + RESULTS_PATH + '/plots/' + filename + '.pdf'\n",
        "print(filepath)\n",
        "plt.title(\"\")\n",
        "plt.savefig(filepath, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "E0TADxxnDCxw",
        "outputId": "c64a548e-0486-438b-8d4e-d3e418cacc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oversampled & 0.34 (0.05) & 0.57 (0.02) & 0.56 (0.05) & 0.53 (0.03) & 0.48 (0.04) & 0.51 (0.02) \\\\ dataset & \\small [0.4, 0.5, 0.1] & \\small [0.9, 0.8, 0.0] & \\small [0.9, 0.8, 0.1] & \\small [0.8, 0.8, 0.0] & \\small [0.7, 0.7, 0.0] & \\small [0.8, 0.7, 0.0]\n",
            "/content/drive/MyDrive/DLDH/results/plots/results-unbalanced-individual.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:86: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Annotators"
      ],
      "metadata": {
        "id": "N2JX4193rNCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annotators = ['T', 'A', 'P', 'B', 'K', 'GoldStandard']\n",
        "\n",
        "foldername = '2022-03-11-18:55:24 | redewiedergabe | EPOCHS 3 | FOLDS 10'\n",
        "filename = 'results_all_annotators_ternary_unbalanced'\n",
        "\n",
        "annotator_names = []\n",
        "dfs = pd.DataFrame()\n",
        "for a in annotators:\n",
        "  path = ROOT_PATH + RESULTS_PATH + '/runs/' + foldername + '/results_' + a + '.csv'\n",
        "  df = open_csv_annotators(path, a)\n",
        "  dfs = pd.concat([dfs, df])\n",
        "\n",
        "plt.figure(figsize=(13,3))\n",
        "plt.ylabel(\"Macro-F1\", fontweight='bold')\n",
        "plt.xlabel(\"Annotator\", fontweight='bold')\n",
        "mean = []\n",
        "std = []\n",
        "mean_macro = []\n",
        "std_macro = []\n",
        "print(annotator_names)\n",
        "\n",
        "for a in annotator_names:\n",
        "  df = dfs[dfs['annotator'] == a]\n",
        "  accuracy = df[df['measure'] == 'evaluation_accuracy'].results.values[0]\n",
        "  mean.append(np.mean(accuracy))\n",
        "  std.append(np.std(accuracy))\n",
        "  macro_f1 = df[df['measure'] == 'evaluation_macro_f1'].results.values[0]\n",
        "  mean_macro.append(np.mean(macro_f1))\n",
        "  std_macro.append(np.std(macro_f1))\n",
        "\n",
        "plt.errorbar(annotator_names, mean_macro, yerr=std_macro, capsize=10, ls='none', label='Standard Deviation')\n",
        "plt.scatter(annotator_names, mean_macro, c='black', zorder=2, label='Mean')\n",
        "for i, v in enumerate(mean_macro):\n",
        "  plt.annotate(round(v, 2), (i, v),xytext=(10, 0), textcoords='offset points')\n",
        "filepath = ROOT_PATH + RESULTS_PATH + '/plots/' + filename + '.pdf'\n",
        "print(filepath)\n",
        "plt.title(\"\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.savefig(filepath, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "7AoNx_2zFWY_",
        "outputId": "9a708841-a8fb-42bb-dce5-703990cfdd01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DLDH/results/runs/2022-03-11-18:55:24 | redewiedergabe | EPOCHS 3 | FOLDS 10/results_T.csv\n",
            "/content/drive/MyDrive/DLDH/results/runs/2022-03-11-18:55:24 | redewiedergabe | EPOCHS 3 | FOLDS 10/results_A.csv\n",
            "/content/drive/MyDrive/DLDH/results/runs/2022-03-11-18:55:24 | redewiedergabe | EPOCHS 3 | FOLDS 10/results_P.csv\n",
            "/content/drive/MyDrive/DLDH/results/runs/2022-03-11-18:55:24 | redewiedergabe | EPOCHS 3 | FOLDS 10/results_B.csv\n",
            "/content/drive/MyDrive/DLDH/results/runs/2022-03-11-18:55:24 | redewiedergabe | EPOCHS 3 | FOLDS 10/results_K.csv\n",
            "/content/drive/MyDrive/DLDH/results/runs/2022-03-11-18:55:24 | redewiedergabe | EPOCHS 3 | FOLDS 10/results_GoldStandard.csv\n",
            "['T', 'A', 'P', 'B', 'K', 'GoldStandard']\n",
            "/content/drive/MyDrive/DLDH/results/plots/results_all_annotators_ternary_unbalanced.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 936x216 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAADQCAYAAACa5/eTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV5Z3H8c+PIGDUVjYdJECgEIUIREkUl2rQsogSsaKBphbGYlyro9atGQFpM9DWKUqxFaQarRGwUjXjzshmEZGgiBoVLGuQUQSXQkQg/OaPexJvQlZuLjeB7/v1uq+c+5znec7vxEvML89yzN0RERERERGJRLNYByAiIiIiIk2fEgsREREREYmYEgsREREREYmYEgsREREREYmYEgsREREREYmYEgsREREREYlY81gHcDC0a9fOExMTYx2GiIiIiEiTtWLFis/dvX115w+LxCIxMZHCwsJYhyEiIiIi0mSZ2YaazmsqlIiIiIiIREyJhYiIiIiIREyJhYiIiIiIROywWGNRlT179lBcXMyuXbtiHYrEWKtWrUhISOCII46IdSgiIiIiTdZhm1gUFxdzzDHHkJiYiJnFOhyJEXdn27ZtFBcX07Vr11iHIyIiItJkHbaJxa5du5RUCGZG27Zt2bp1a4P0N2Xeau5/dU2D9AVw0/k9uHlgUoP1JyIiIhIth21iASipEKBhPwc3D0yqNRHInL4UgDlXn9Fg1xURERGJNS3ejiEz46c//Wn5+71799K+fXsuuuiiGEYlIiIiIlJ/h/WIRawdddRRvPfee3zzzTcceeSRzJs3j44dO8Y6LBEREYkiTZuVQ5USizrKz88nJyeHjRs30rlzZ3Jzc8nKyoq436FDh/L8888zYsQIZs2axahRo3jttdcA2LlzJ7/4xS9477332LNnDxMmTODiiy9m/fr1XHHFFezcuROAadOmceaZZ7Jw4UImTJhAu3bteO+99+jXrx+PP/64pnyJiIg0Ipo2K4eqqE6FMrMhZvaRmX1sZndWU+dyMysys/fN7Imw8lIzWxm8CsLKu5rZsqDPOWbWIpr3AKGkIjs7mw0bNuDubNiwgezsbPLz8yPue+TIkcyePZtdu3axatUqTj/99PJzubm5nHfeebz55pssWLCA2267jZ07d3Lccccxb9483nrrLebMmcONN95Y3ubtt9/mvvvuo6ioiLVr17JkyZKIYxQRERERqU3UEgsziwMeAC4AegGjzKxXpTo9gLuAs9w9GfiPsNPfuHtK8MoIK/8tMMXduwNfAD+P1j2UycnJoaSkpEJZSUkJOTk5Effdp08f1q9fz6xZsxg6dGiFc6+88gqTJ08mJSWF9PR0du3axcaNG9mzZw9XXXUVvXv35rLLLqOoqKi8zWmnnUZCQgLNmjUjJSWF9evXRxyjiIiIiEhtojkV6jTgY3dfC2Bms4GLgaKwOlcBD7j7FwDu/llNHVpoTs95wE+CokeBCcCfGzTySjZu3Fiv8vrKyMjgl7/8JQsXLmTbtm3l5e7O3LlzOfHEEyvUnzBhAscffzzvvPMO+/bto1WrVuXnWrZsWX4cFxfH3r17GyRGEREREZGaRHMqVEdgU9j74qAsXBKQZGZLzOwNMxsSdq6VmRUG5cODsrbAl+5e9ttyVX02uM6dO9ervL6uvPJKxo8fT+/evSuUDx48mD/+8Y+4OxCa5gTw1Vdf0aFDB5o1a8Zf//pXSktLGyQOEREREZEDFevtZpsDPYB0YBTwkJkdG5zr4u6phEYn7jOzH9SnYzPLDhKTwkgffpabm0t8fHyFsvj4eHJzcyPqt0xCQkKFdRJl7r77bvbs2UOfPn1ITk7m7rvvBuC6667j0UcfpW/fvnz44YccddRRDRKHiIiIiMiBiuZUqM1Ap7D3CUFZuGJgmbvvAdaZ2WpCicZyd98M4O5rzWwhcAowFzjWzJoHoxZV9UnQbgYwAyA1NdUjuZGy3Z8aeleoHTt27FeWnp5Oeno6AEceeSTTp0/fr06PHj1YtWpV+fvf/va3+7WF0G5RIiIiIiIHQzRHLJYDPYJdnFoAI4GCSnWeITRagZm1IzQ1aq2ZtTazlmHlZwFFHpoTtAAYEbQfDTwbxXsol5WVxfr169m3bx/r169vkK1mRUREREQOFVFLLIIRhRuAl4EPgCfd/X0zm2hmZbs8vQxsM7MiQgnDbe6+DegJFJrZO0H5ZHcvW/R9B3CLmX1MaM3FX6J1DyIiIiIiUjdRfUCeu78AvFCpbFzYsQO3BK/wOq8DFVcyf3duLaEdp0REREREpJGI9eJtERERERE5BCixEBERERGRiEV1KlRTMmXeau5/dU2D9XfT+T24eWBSg/UnIiIiItKYKbEI3DwwqdZEIHP6UgDmXH1Gg1wzNzeXJ554gri4OJo1a8b06dM5/fTTue+++8jOzt7v2RkHKjExkcLCQtq1a3dA7fPy8igsLNxv+9q8vDxuu+02EhIS2LFjB926dWP8+PGceeaZB3SdcePGcc455/CjH/2oxlgGDRrECSecAMDYsWO55ZZb6NWr1wFdU0REREQahhKLGFm6dCnPPfccb731Fi1btuTzzz9n9+7dANx333389Kc/bbDEor5KS0uJi4urU93MzMzyhGPBggX8+Mc/ZsGCBfTs2bPe1504cWKtdfLy8jj55JPLE4uZM2fW+zoiIiIi0vC0xiJGtmzZQrt27WjZsiUA7dq144QTTmDq1Kl88sknDBgwgAEDBgBw7bXXkpqaSnJyMuPHjy/vIzExkfHjx3PqqafSu3dvPvzwQwC2bdvGoEGDSE5OZuzYsYQ23woZPnw4/fr1Izk5mRkzZpSXH3300dx666307duXpUuX8sgjj5CUlMRpp53GkiVL6nRPAwYMIDs7u7zff/7znwwZMoR+/frxwx/+kA8//JCvvvqKLl26sG/fPgB27txJp06d2LNnD2PGjOGpp54CQklGWloaJ598MtnZ2bg7Tz31FIWFhWRlZZGSksI333xDeno6hYWFAMyaNYvevXtz8sknc8cdd1S4t5ycHPr27Uv//v359NNP6/cfS0RERERqpRGLGBk0aBATJ04kKSmJH/3oR2RmZnLuuedy44038oc//IEFCxaUT13Kzc2lTZs2lJaWcv7557Nq1Sr69OkDhBKSt956iz/96U/ce++9zJw5k3vuuYezzz6bcePG8fzzz/OXv3z3qI+HH36YNm3a8M0335CWlsall15K27Zt2blzJ6effjr//d//zZYtW/jJT37CihUr+P73v8+AAQM45ZRT6nRfp556avnTwrOzs3nwwQfp0aMHy5Yt47rrrmP+/PmkpKSwaNEiBgwYwHPPPcfgwYM54ogjKvRzww03MG5caGfiK664gueee44RI0Ywbdo07r33XlJTUyvU/+STT7jjjjtYsWIFrVu3ZtCgQTzzzDMMHz6cnTt30r9/f3Jzc7n99tt56KGH+M///M8D+w8nUg9auyUiIocTJRYxcvTRR7NixQpee+01FixYQGZmJpMnT2bMmDH71X3yySeZMWMGe/fuZcuWLRQVFZUnFj/+8Y8B6NevH3//+98BWLx4cfnxhRdeSOvWrcv7mjp1Kk8//TQAmzZtYs2aNbRt25a4uDguvfRSAJYtW0Z6ejrt27cHQtOdVq9eXaf7Khsd2bFjB6+//jqXXXZZ+blvv/22vL85c+YwYMAAZs+ezXXXXbdfPwsWLOB3v/sdJSUlbN++neTkZIYNG1btdZcvX14h5qysLBYvXszw4cNp0aIFF110Ufn3ad68eXW6F5FIxWLtloiISKwosYihuLg40tPTSU9Pp3fv3jz66KP7JRbr1q3j3nvvZfny5bRu3ZoxY8awa9eu8vNlU6ni4uLYu3dvjddbuHAh//u//8vSpUuJj48nPT29vK9WrVrVeV1FTd5++2169uzJvn37OPbYY1m5cuV+dTIyMvjVr37F9u3bWbFiBeedd16F87t27eK6666jsLCQTp06MWHChAr3XF9HHHEEZgbU7fskIiIiIvWnNRYx8tFHH7FmzXdTJFauXEmXLl0AOOaYY/jXv/4FwNdff81RRx3F97//fT799FNefPHFWvs+55xzeOKJJwB48cUX+eKLLwD46quvaN26NfHx8Xz44Ye88cYbVbY//fTTWbRoEdu2bWPPnj387W9/q9M9LVq0iBkzZnDVVVfxve99j65du5a3dXfeeecdIDRak5aWxk033cRFF120X0JTlkS0a9eOHTt2lK+7qPy9CXfaaaexaNEiPv/8c0pLS5k1axbnnntuneIWERERkchpxCJGduzYwS9+8Qu+/PJLmjdvTvfu3csXPWdnZzNkyBBOOOEEFixYwCmnnMJJJ51Ep06dOOuss2rte/z48YwaNYrk5GTOPPNMOnfuDMCQIUN48MEH6dmzJyeeeCL9+/evsn2HDh2YMGECZ5xxBsceeywpKSnVXmvOnDn84x//oKSkhK5duzJ37tzyHaHy8/O59tpr+c1vfsOePXsYOXIkffv2BULToS677DIWLly4X5/HHnssV111FSeffDL/9m//RlpaWvm5MWPGcM0113DkkUeydOnSCjFPnjyZAQMG4O5ceOGFXHzxxbV+r0RERESkYVj4jkGHqtTUVC/bOajMBx98UO8tUTUX+tB1IJ+HA6XPkYTT50FEqqKfDdIYmdkKd0+t7rxGLAL12b0l8c7na62j3VtERERE5HCixCJQl91bRERERESkalq8LSIiIiIiETusE4vDYX2J1E6fAxEREZHIRTWxMLMhZvaRmX1sZndWU+dyMysys/fN7ImgLMXMlgZlq8wsM6x+npmtM7OVwav6LYtq0KpVK7Zt26ZfKg9z7s62bdto1apVrEMRERERadKitsbCzOKAB4CBQDGw3MwK3L0orE4P4C7gLHf/wsyOC06VAD9z9zVmdgKwwsxedvcvg/O3uft3Dzc4AAkJCRQXF7N169ZIupFDQKtWrUhISIh1GCIiIhF56aWXuOmmmygtLWXs2LHceef+f9N98sknmTBhAmZG3759eeKJJ1i5ciXXXnstX3/9NXFxceTk5JCZmVnFFURqFs3F26cBH7v7WgAzmw1cDBSF1bkKeMDdvwBw98+Cr6vLKrj7J2b2GdAe+JIGcsQRR9C1a9eG6k5EREQkZkpLS7n++uuZN28eCQkJpKWlkZGRQa9evcrrrFmzhkmTJrFkyRJat27NZ599BkB8fDyPPfYYPXr04JNPPqFfv34MHjyYY489Nla3I01UNKdCdQQ2hb0vDsrCJQFJZrbEzN4wsyGVOzGz04AWwD/DinODKVJTzKxlQwcuIiIi0pS8+eabdO/enW7dutGiRQtGjhzJs88+W6HOQw89xPXXX0/r1q0BOO640ESRpKQkevToAcAJJ5zAcccdpxkdckBivXi7OdADSAdGAQ+ZWXl6bGYdgL8C/+7u+4Liu4CTgDSgDXBHVR2bWbaZFZpZof5xiIiIyKFs8+bNdOrUqfx9QkICmzdvrlBn9erVrF69mrPOOov+/fvz0ksv7dfPm2++ye7du/nBD34Q9Zjl0BPNxGIz0CnsfUJQFq4YKHD3Pe6+DlhNKNHAzL4HPA/kuPsbZQ3cfYuHfAs8QmjK1X7cfYa7p7p7avv27RvspkRERESaor1797JmzRoWLlzIrFmzuOqqq/jyy+9mmW/ZsoUrrriCRx55hGbNYv23Z2mKovmpWQ70MLOuZtYCGAkUVKrzDKHRCsysHaGpUWuD+k8Dj1VepB2MYmBmBgwH3oviPYiIiIgcVPn5+Tz3q0t48pqzSExMJD8/v9Y2HTt2ZNOm72agFxcX07FjxRnoCQkJZGRklK8zTUpKYs2aNQB8/fXXXHjhheTm5tK/f/+GvSE5bEQtsXD3vcANwMvAB8CT7v6+mU00s4yg2svANjMrAhYQ2u1pG3A5cA4wpoptZfPN7F3gXaAd8Jto3YOIiIjIwZSfn092djYl2z8FnA0bNpCdnV1rcpGWlsaaNWtYt24du3fvZvbs2WRkZFSoM3z4cBYuXAjA559/zurVq+nWrRu7d+/mkksu4Wc/+xkjRoyI0p3J4SCau0Lh7i8AL1QqGxd27MAtwSu8zuPA49X0eV7DRyoiIiISezk5OZSUlFQoKykpIScnh6ysrGrbNW/enGnTpjF48GBKS0u58sorSU5OZty4caSmppKRkcHgwYN55ZVX6NWrF3Fxcfz+97+nbdu2PP744yxevJht27aRl5cHQF5eHikpB/SoMDmM2eHwgLjU1FQvLCyMdRgiAGROXwrAnKvPiHEk0hjo8yAi4Zo1a1blw3vNjH379lXRQuTgMbMV7p5a3XmtzBERERFpJDp37lyvcpHGRImFiIiISCORm5tLfHx8hbL4+Hhyc3NjFJFI3SmxEBEREWkksrKymDFjBvFtjgeMLl26MGPGjBrXV4g0FlFdvC0iIiIi9ZOVlUXBjm6A1l9J06IRCxERERERiZgSCxERERERiZgSCxERERERiZgSCxERERERiZgWb4uIiETZlHmruf/VNQ3W303n9+DmgUkN1p+ISENQYiEiIhJlNw9MqjUR0FPYRaSp01QoERERERGJ2AElFmZ2ipmNa+hgRERERESkaTrQEYtTgfENGYiIiIiIiDRdNa6xMLNV1ZxqHYVYRERERESkiapt8fbJNZzzhgxERERERESartqmQm0C/svdm4W/gOy6dG5mQ8zsIzP72MzurKbO5WZWZGbvm9kTYeWjzWxN8BodVt7PzN4N+pxqZlaXWEREREREJHpqG7H4czV1PgIeq6mhmcUBDwADgWJguZkVuHtRWJ0ewF3AWe7+hZkdF5S3IbSGI5XQyMiKoO0XQUxXAcuAF4AhwIu13aiIiIiIiERPjYmFu0+upvw14LVa+j4N+Njd1wKY2WzgYqAorM5VwANBwoC7fxaUDwbmufv2oO08YIiZLQS+5+5vBOWPAcNRYiEiIiIiElO1Ld7OAJYD/wd0Av7P3XfXse+OhKZSlSkGTq9UJym4zhIgDpjg7i9V07Zj8Cquoryq2LMJpmx17ty5jiGLiIiIiBw8U+at5v5X1zRYfzed36PWB3JGS21ToZ4GRgGvAusITWua38DX7wGkAwnAYjPr3RAdu/sMYAZAamqqFpqLiIiISKNz88CkWhOBzOlLAZhz9RkHI6QDVtvibavmuC42ExrlKJMQlIUrBgrcfY+7rwNWE0o0qmu7OTiuqU8RERERETnI6vKAvKP57rkVx5hZm7JXLe2WAz3MrKuZtQBGAgWV6jxDaLQCM2tHaGrUWuBlYJCZtTaz1sAg4GV33wJ8bWb9g92gfgY8W4d7EBERERGRKKptKhTAQ2HHfw879prau/teM7uBUJIQBzzs7u+b2USg0N0L+C6BKAJKgdvcfRuAmf2aUHICMLFsITdwHZAHHElo0bYWbouIiIiIxFhticViIngQnru/QGhL2PCycWHHDtwSvCq3fRh4uIryQmp+cJ+IiIiIiBxktW03m36Q4hARERERkSasLmssADCzY81srZk17uXoIiIiIiJy0NU5sSC0TiKR0NoGERERERGRcvVJLEQkBl566SVOPPFEunfvzuTJk/c7n5eXR/v27UlJSSElJYWZM2eWn7v99ttJTk6mZ8+e3HjjjYSWNYmIiIg0vLrsClXmS2AAsDJKsYhIJaWlpVx//fXMmzePhIQE0tLSyMjIoFevXhXqZWZmMm3atAplr7/+OkuWLGHVqlUAnH322SxatIj09PSDFb6IiIgcRuo0YmFmRwB3A78DXjGzcUGZiETRm2++Sffu3enWrRstWrRg5MiRPPts3R7dYmbs2rWL3bt38+2337Jnzx6OP/74KEcsIiIih6u6ToX6HTAO6Be8xgO/jVZQIhKyefNmOnX67iH0CQkJbN68/8Pm586dS58+fRgxYgSbNm0C4IwzzmDAgAF06NCBDh06MHjwYHr27HnQYhcREZHDS10Ti8uBR4B44ChCD6jLjFJMIoes/Px8nvvVJTx5zVkkJiaSn58fcZ/Dhg1j/fr1rFq1ioEDBzJ69GgAPv74Yz744AOKi4vZvHkz8+fP57XXXov4ehJbWnMjIiKNVV0TiyOBj9x9t7t/C6xGu0OJ1Et+fj7Z2dmUbP8UcDZs2EB2dnaNyUXHjh3LRyAAiouL6dixY4U6bdu2pWXLlgCMHTuWFStWAPD000/Tv39/jj76aI4++mguuOACli5d2vA3JgdN2ZqbF198kaKiImbNmkVRUdF+9TIzM1m5ciUrV65k7NixQMU1N++99x7Lly9n0aJFB/sWRETkEFbXxGIxkGtmr5nZYuDXwMKoRSVyCMrJyaGkpKRCWUlJCTk5OdW2SUtLY82aNaxbt47du3cze/ZsMjIyKtTZsmVL+XFBQUH5dKfOnTuzaNEi9u7dy549e1i0aJGmQjVxWnMjIiKNWV13hboBaAOcHbxfDPwiKhGJHKI2btxYr3KA5s2bM23aNAYPHkxpaSlXXnklycnJjBs3jtTUVDIyMpg6dSoFBQU0b96cNm3akJeXB8CIESOYP38+vXv3xswYMmQIw4YNi8atyUFS1ZqbZcuW7Vdv7ty5LF68mKSkJKZMmUKnTp0qrLlxd2644QYlmiIxMmXeau5/dU2d6ibe+XytdW46vwc3D0yKNCyRiNWaWJhZHPBj4FagCMDdd0Y5LpFDTufOndmwYUOV5TUZOnQoQ4cOrVA2ceLE8uNJkyYxadKk/drFxcUxffr0A4xWmqphw4YxatQoWrZsyfTp0xk9ejTz58+vsOYGYODAgbz22mv88Ic/jHHEIoefmwcmKRGQQ1KtU6HcvRS4HUh2951KKkQOTG5uLvHx8RXK4uPjyc3NjVFEEmv1XcyvNTciItKY1XWNRQFwi5ldaGanlr2iGZjIoSYrK4sZM2YQ3+Z4wOjSpQszZswgKysr1qFJDBzIYn6tuRERkcasronFNUAyoQRjedhLROohKyuLi/7raS5/cAnr169XUnEYO5DF/OFrbnr27Mnll19evuamoKAAgKlTp5KcnEzfvn2ZOnVqhTU3P/jBD+jduzd9+/alb9++WnNzCDjQ7YcXLFhQXpaSkkKrVq145plnDnb4InKIsbrsY25mecB+Fd3932tpNwS4H4gDZrr75ErnxwC/B8qe+DXN3Wea2QBgSljVk4CR7v5MEMu5wFfBuTHuvrKmOFJTU72wsLCmKiIHTeb00PSTOVefEeNIJJaaNWtW5XMkzIx9+/bFICKJtfr+bCgtLSUpKYl58+aRkJBAWloas2bNolevXuV18vLyKCwsZNq0adX2s337drp3705xcfF+0zVFpHFoLL87mNkKd0+t7nyddoVy9zEHcOE44AFgIFAMLDezAnevvOn6HHe/odL1FgApQT9tgI+BV8Kq3ObuT9U3JhGRxuJAF/OLlAnffhgo3344PLGoi6eeeooLLrhASYWIRKxOU6HM7DEzmxD2/h4ze6yWZqcBH7v7WnffDcwGLj6AGEcAL7p7Sa01RUSaCC3ml0hVtf3w5s2b96s3d+5c+vTpw4gRIyos/i8ze/ZsRo0aFdVYReTwUNc1FpcC4X9a20BoC9qadATCf4IVB2X79W1mq8zsKTPrVMX5kcCsSmW5QZspZtayljhERBodLeaXg2HYsGGsX7+eVatWMXDgQEaPHl3h/JYtW3j33XcZPHhwjCIUkUNJXROLLwmtayiTzndrHCLxP0Ciu/cB5gGPhp80sw5Ab+DlsOK7CK25SCP00L47qurYzLLNrNDMCrdu3doAoYqINCwt5pcy9d16GCLbfrjMk08+ySWXXMIRRxzRAHchIo1JLDZ3qGti8T/Az8xsi5ltAbII7RBVk81A+AhEAt8t0gbA3be5+7fB25lAv0p9XA487e57wtps8ZBvgUcITbnaj7vPcPdUd09t3759LaGKiIjExoFsPQyRbT9cZtasWZoGJXIIKi0t5frrr+fFF1+kqKiIWbNmUVRUeZkzZGZmsnLlSlauXMnYsWMBGDBgQHnZ/PnziY+PZ9CgQXW6bl0Ti9uAPEK7O8UFx7fX0mY50MPMuppZC0JTmiokI8GIRJkM4INKfYyi0jSosjZmZsBw4L063oOIiEijcyBbD0Nk2w8DrF+/nk2bNnHuuedWcwURaarCN3do0aJF+eYO9VXfzR3quivUv4Ar6xOIu+81sxsITWOKAx529/fNbCJQ6O4FwI1mlgHsBbYDY8ram1kioRGPRZW6zjez9oABKwk9Y0NERKRJ2rhxY73Kww0dOpShQ4dWKJs4cWL58aRJk5g0aVKVbRMTE6tc7C0iTV9VmzssW7Zsv3pz585l8eLFJCUlMWXKlAptILS5wy233FLn69YpsQhGCSYQWu/QKih2d688dakCd38BeKFS2biw47sIrZmoqu16qljs7e7n1SVmERGRpkBbD4tILAwbNoxRo0bRsmVLpk+fzujRo5k/f375+QPZ3KGuU6FmAj8HTif0BO4UoGvdQxcREZGqaOthEalJU9rcoa6JxZlA2VjqhcCDhB5+JyIiIhHQ1sMiUp2mtrlDnaZCAS2AdYTWNaQA/wJuAu6u19VERERkP1lZWRTsCD1Be87VZ8Q4GhFpLGra3KGmPz6Eb+5QWlrKlVdeWb65Q2pqKhkZGUydOpWCggKaN29OmzZtGmRzh7omFuuBdsAq4HeAAx/V60oiIiIiIlJnTW1zh7omFpcBuwktxM4hlFho8qeIiIiISJQ0tc0dalxjYWalZlYKvEtohOIdQg+tywyORUREREQkCpra5g61jVgYodGJT4Avox+OiIiIiIgA5esosm+8lZLtn9GlS2dyc3Mb7eYOtSUWjxCaBtUOeA14xN3nRT0qERERERFpUps71DgVyt1/DnQAriP0FOyXzGy9mQ05GMGJiIiIiEjTUOtzLNx9J7CW0HazuwmNXhwT5bhERERERKQJqXEqlJnlAGOAbsAy4BfAHHf/V/RDaxqmzFvN/a+uabD+bjq/BzcPTGqw/kREREREDoba1lj8mtDi7bXA50AGkGFmAO7uF0c3vMbv5oFJtSYCmdOXAo1/Xl0nDX4AAA+9SURBVJyIiIiIyIGqy3MsDPhB8ArnDR+OiIiIiIg0RbUlFl0PShQiIiIiItKk1ZhYuPv+j/oTERERERGppNZdoURERERERGoT1cTCzIaY2Udm9rGZ3VnF+TFmttXMVgavsWHnSsPKC8LKu5rZsqDPOWbWIpr3ICIiIiIitYtaYmFmccADwAVAL2CUmfWqouocd08JXjPDyr8JK88IK/8tMMXduwNfAD+P1j2IiIiIiEjdRHPE4jTgY3df6+67gdlARNvTWmif2/OAp4KiR4HhEUUpIiIiIiIRi2Zi0RHYFPa+OCir7FIzW2VmT5lZp7DyVmZWaGZvmFlZ8tAW+NLd99bSJ2aWHbQv3Lp1a4S3IiIiIiIiNYn14u3/ARLdvQ8wj9AIRJku7p4K/AS4z8wqP0ejRu4+w91T3T21ffv2DRexiIiIiIjsJ5qJxWYgfAQiISgr5+7b3P3b4O1MoF/Yuc3B17XAQuAUYBtwrJmVbZO7X58iIiIiInLwRTOxWA70CHZxagGMBArCK5hZh7C3GcAHQXlrM2sZHLcDzgKK3N2BBcCIoM1o4Nko3oOIiIiIiNRBbU/ePmDuvtfMbgBeBuKAh939fTObCBS6ewFwo5llAHuB7cCYoHlPYLqZ7SOU/Ex296Lg3B3AbDP7DfA28Jdo3YOIiIiIiNRN1BILAHd/AXihUtm4sOO7gLuqaPc60LuaPtcS2nFKREREREQaiVgv3pYqvPTSS5x44ol0796dyZMn73c+Ly+P9u3bk5KSQkpKCjNnzqxw/uuvvyYhIYEbbrjhYIUsIiIiIoe5qI5YSP2VlpZy/fXXM2/ePBISEkhLSyMjI4NevSo+WzAzM5Np06ZV2cfdd9/NOeecczDCFREREREBNGLR6Lz55pt0796dbt260aJFC0aOHMmzz9Z9ffqKFSv49NNPGTRoUBSjFBERERGpSIlFI7N582Y6dfpul96EhAQ2b95/R925c+fSp08fRowYwaZNoecQ7tu3j1tvvZV77733oMUrIiIiIgJKLJqkYcOGsX79elatWsXAgQMZPXo0AH/6058YOnQoCQkJMY5QRERERA43SiyiLD8/n+d+dQlPXnMWiYmJ5Ofn11i/Y8eO5SMQAMXFxXTs2LFCnbZt29KyZUsAxo4dy4oVKwBYunQp06ZNIzExkV/+8pc89thj3HnnnQ18RyIiIiIi+9Pi7SjKz88nOzubkpISADZs2EB2djYAWVlZVbZJS0tjzZo1rFu3jo4dOzJ79myeeOKJCnW2bNlChw6hZwsWFBTQs2fP8uuVycvLo7CwsMpdpUREREREGppGLKIoJyenPKkoU1JSQk5OTrVtmjdvzrRp0xg8eDA9e/bk8ssvJzk5mXHjxlFQEHpw+dSpU0lOTqZv375MnTqVvLy8aN6GiIiIiEitNGIRRRs3bqxXeZmhQ4cydOjQCmUTJ04sP540aRKTJk2qsY8xY8YwZsyYugUqIiIiIhIhjVhEUefOnetVLiIiIiLSVGnEIopyc3MrrLEAiI+PJzc3N4ZRiYiIiEhjMWXeau5/dU2d6ibe+XytdW46vwc3D0yKNKwDosQiisoWaGffeCsl2z+jS5fO5ObmVrtwW0REDk2H0i8OItKwbh6YdMj8e1ZiEWVZWVkU7OgGwJyrz4hxNCIiEguH0i8OIiLV0RoLERERERGJmBILERERERGJWFQTCzMbYmYfmdnHZrbfI6DNbIyZbTWzlcFrbFCeYmZLzex9M1tlZplhbfLMbF1Ym5Ro3oOIiIiIiNQuamsszCwOeAAYCBQDy82swN2LKlWd4+43VCorAX7m7mvM7ARghZm97O5fBudvc/enohW7iIiIiIjUTzRHLE4DPnb3te6+G5gNXFyXhu6+2t3XBMefAJ8B7aMWqYiIiIiIRCSaiUVHYFPY++KgrLJLg+lOT5lZp8onzew0oAXwz7Di3KDNFDNr2aBRi4iIiIhIvcV68fb/AInu3geYBzwaftLMOgB/Bf7d3fcFxXcBJwFpQBvgjqo6NrNsMys0s8KtW7dGK34RERERESG6icVmIHwEIiEoK+fu29z92+DtTKBf2Tkz+x7wPJDj7m+EtdniId8CjxCacrUfd5/h7qnuntq+vWZRiYiIiIhEUzQTi+VADzPramYtgJFAQXiFYESiTAbwQVDeAngaeKzyIu2yNmZmwHDgvajdgYiIiIiI1EnUdoVy971mdgPwMhAHPOzu75vZRKDQ3QuAG80sA9gLbAfGBM0vB84B2ppZWdkYd18J5JtZe8CAlcA10boHERERERGpm6glFgDu/gLwQqWycWHHdxFaM1G53ePA49X0eV4DhykiIiIiIhGKamIhInI4mzJvNfe/uqZOdRPvfL7WOjed34ObByZFGpaIiEhUKLEQEYmSmwcmKREQEZHDRqy3mxURERERkUOAEgsREREREYmYEgsREREREYmYEgsREREREYmYFm9HSLu+iIiIiIgosYiYdn0REREREdFUKBERERERaQBKLEREREREJGJKLEREREREJGJaYyHSgLSYX0RERA5X5u6xjiHqUlNTvbCwMNZhiIiIiIg0WWa2wt1TqzuvqVAiIiIiIhIxJRYiIiIiIhIxJRYiIiIiIhIxJRYiIiIiIhIxJRYiIiIiIhIxJRYiIiIiIhKxw2K7WTPbCmyIcRjtgM9jHIM0Hvo8SDh9HqSMPgsSTp8HCdcYPg9d3L19dScPi8SiMTCzwpr2/ZXDiz4PEk6fBymjz4KE0+dBwjWFz4OmQomIiIiISMSUWIiIiIiISMSUWBw8M2IdgDQq+jxIOH0epIw+CxJOnwcJ1+g/D1pjISIiIiIiEdOIhYiIiIiIREyJRRSZWVszWxm8/s/MNoe9bxHr+OTgM7PhZuZmdlKsY5HYM7PS4OfBe2b2NzOLj3VMEhthn4V3zOwtMzsz1jFJ7JjZjrDjoWa22sy6xDImATM73syeMLO1ZrbCzJaa2SU11E83s+eqObfezNoFxzlm9r6ZrQp+DpwelP9HQ/5/IfyaB9h+jJlNq6mOEosocvdt7p7i7inAg8CUsvfuvjvW8UlMjAL+EXwV+Sb4eXAysBu4JtYBScyUfRb6AncBk2IdkMSemZ0PTAUucPdYP4/rsGZmBjwDLHb3bu7eDxgJJETY7xnARcCp7t4H+BGwKTj9H0DM/uBkZnH1baPEQuQgMbOjgbOBnxP6YSQS7jWge6yDkEbhe8AXsQ5CYsvMzgEeAi5y93/GOh7hPGC3uz9YVuDuG9z9j2bWysweMbN3zextMxtQuXEwi+WVYGRiJmDBqQ7A5+7+bdDn5+7+iZndCJwALDCzBUEffzazwqCPe8L6Xm9m9wSjne+WzYqo4ZqY2TPBqMv7ZpYdVr7DzP7bzN4BzjCzfw9GzN4Ezqrtm6TEQuTguRh4yd1XA9vMrF+sA5LGwcyaAxcA78Y6FomZI4MpEB8CM4FfxzogiamWhP46PtzdP4x1MAJAMvBWNeeuB9zdexOakfCombWqVGc88A93TwaeBjoH5a8AnYJf3v9kZucS6mwq8AkwwN3LEpWc4AF5fYBzzaxPWP+fu/upwJ+BX9ZyTYArg1GXVOBGM2sblB8FLAtGT/8J3EMooTgb6FXL90iJhchBNAqYHRzPRtOhJPhlEigENgJ/iXE8EjtlU6FOAoYAjwVTL+TwtAd4ndAItzRCZvZAsCZqOaFfuh8HCBLBDUBSpSbnhNV5nmBU0t13AP2AbGArMMfMxlRz2cvN7C3gbUKJTvgv+n8Pvq4AEmu6ZuDGYFTiDaAT0CMoLwXmBsenAwvdfWswhX9O9d+RkOa1VRCRyJlZG0LDqL3NzIE4wM3sNteez4ezb4I1WCLl3H1psMCyPfBZrOORmNgHXA68ama/cvf/inVAwvvApWVv3P364N9pIVAcScfuXgosBBaa2bvAaCAvvI6ZdSU0EpHm7l+YWR4QPirybfC1lFp+vzezdEJrOc5w9xIzWxjW164gngOiEQuRg2ME8Fd37+Luie7eCVgH/DDGcYlIIxPMj44DtsU6Fokddy8BLgSyzEwjF7E3H2hlZteGlZUtrH4NyAIwsyRCU44+qtR+MfCToM4FQOvg+EQz6xFWL4XQiAfAv4BjguPvATuBr8zseELTZ2tT5TWB7wNfBEnFSUD/atovIzTlqq2ZHQFcVtsFNWIhcnCMAn5bqWxuUL744IcjIo1M2bQ4CC2wHB3JXw3l0ODu281sCLDYzLa6e0GsYzpcubub2XBgipndTmja0k7gDuBZ4M/BaMNeYIy7f1tpNuM9wCwze5/QNLeNQfnRwB/N7Nig7ceEpkVB6EnbL5nZJ+4+wMzeBj4ktGvUkjqEXd01XwKuMbMPCCVAb1Rzz1vMbAKwFPgSWFlVvXB68raIiIiIiERMU6FERERERCRiSixERERERCRiSixERERERCRiSixERERERCRiSixERERERCRiSixERKRaZna9mXnwOjGK1+llZhOCBzfVpf51wTaIIiLSSCixEBGRmmQSegowhJ4EHC29gPFAeh3rXxfUrzcz0zOcRESiQImFiIhUycxOAM4CngQ+IZRkYGZjghGMWWb2jpl9YWY3BefSg3PPm9kSM/vKzH4f1udVZrbGzHaa2ZtmdraZJQJ/C6qMD9qnm9ntZvaJme02s2IzGx/0kQckB8duZgur67tSvHOCB0U9Ge3vnYjI4UiJhYiIVOcyQv+f+BvwdyDZzHqFnR9A6MmwDkw2sxZh584l9Av8NuCXZtbZzM4L6m8FbgE6AwXAHuC+oF3ZE+mLCD1d9tfAfwCrgAlmdhbwZ6A4qD8KmFhd32bWNiymwcB04LEIviciIlINJRYiIlKdy4HdwIfAsqAsM+z8w+7+APAm0Ao4PuxcgbvfD7wSvO8CDA2Ox7v7dOAvQGsgBVgSnHvP3We7+2fAcUAu8ABwQXC+t7svA74CCOrOr6Hv/pXineruz9T/WyEiIrVRYiEiIvsxs07AGUAL4H3gr8Gp8HUW24Ove4OvcXU855W+Vj7GzI4C/gDsAIYD/xWcalVV/Vr6LvNJNW1ERKQBKLEQEZGqXAYYMAm4JHg9B5wEfO8A+3wh+HqPmV0N/Bz4Angj+ArwQzMbSej/Tw60BP4NuKhSX19A+e5QabX0LSIiB4ESCxERqUomoV/sp7j7M8H0obJRi9sPpMNgylI2oSlOfyC0TiLD3bcB/wBeBX4IzAK+H1ynJXAn302pKnM/8BmhaVJX19K3iIgcBOZe3WiyiIiIiIhI3WjEQkREREREIqbEQkREREREIqbEQkREREREIqbEQkREREREIqbEQkREREREIqbEQkREREREIqbEQkREREREIqbEQkREREREIvb/UAdrg92QV58AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Oversampling"
      ],
      "metadata": {
        "id": "3f9-ttuDB3gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If this parameter is set true, oversampling will be performed on the dataframe\n",
        "oversample_dataframe = False\n",
        "\n",
        "# For the use of the Deepl API (is used to oversample the data set), a Deepl Authentication Key is needed\n",
        "# To obtain such a key, a free trial can be started on the following page: https://www.deepl.com/docs-api/\n",
        "# When 500.000 characters have been translated, a credit card is needed to start a real abonnement and to access the API\n",
        "deepl_auth_key = 'DEEPL_AUTH_KEY'\n",
        "\n",
        "# This parameter specifies the number of iterations after which the intermediate result of the dataframe should be stored repeatedly\n",
        "backup_oversampled_dataframe_after_rows = 40\n",
        "\n",
        "def set_default_staerkegrad_df(df):\n",
        "  \"\"\" \n",
        "  set_default_staerkegrad accepts a dataframe as input. Checks if there is a column named \"Staerkegrad\"\n",
        "  and if there is inserts into empty fields in that column the mostly used value from the column.\n",
        "\n",
        "  :param df: a pandas dataframe\n",
        "  :return: a pandas dataframe, where for every undefined entry in the column \"Staerkgegrad\" the most common value from all rows is set. If there is no such column in the input dataframe, the input dataframe is returned.  \n",
        "  \"\"\"\n",
        "  if ('Stärkegrad (A, B, C)' not in df.columns):\n",
        "    print('[set_default_staerkegrad_df]: Given dataframe does not consist of a column \"Staerkegrad\"!')\n",
        "    return df\n",
        "  else:\n",
        "    most_used_staerkegrad = df['Stärkegrad (A, B, C)'].value_counts().index[0]\n",
        "    df.fillna(value={'Stärkegrad (A, B, C)': most_used_staerkegrad})\n",
        "    return df\n",
        "\n",
        "def translate(text, target_language):\n",
        "  \"\"\"\n",
        "  translate translates the input text into the target language.\n",
        "\n",
        "  :param text: the text to be translated\n",
        "  :param target_language: the deepl target language expression, examples are 'DE' or 'EN-US'\n",
        "  :return: a string, the translation of :param text into the :param target_language\n",
        "  \"\"\"\n",
        "  translator = deepl.Translator(deepl_auth_key) \n",
        "  result = translator.translate_text(text, target_lang=target_language) \n",
        "  translated_text = result.text\n",
        "  return translated_text\n",
        "\n",
        "def translate_into_english_and_back(text):\n",
        "  \"\"\"\n",
        "  translate_into_english_and_back translates the input text into english and then into German.\n",
        "\n",
        "  :param text: the text to be translated\n",
        "  :return: a string. Returned is the result from translating :param text into englisch and after that into German.\n",
        "  \"\"\"\n",
        "  translator = deepl.Translator(deepl_auth_key) \n",
        "  result_eng = translator.translate_text(text, target_lang='EN-US')\n",
        "  result_ger = translator.translate_text(result_eng.text, target_lang='DE')\n",
        "  return result_ger.text\n",
        "\n",
        "def translate_into_target_language_and_back(text, target_language):\n",
        "  \"\"\"\n",
        "  translate_into_target_language_and_back translates the input text into the given target_language and then into German.\n",
        "\n",
        "  :param text: the text to be translated\n",
        "  :param target_language: the language\n",
        "  :return: a string. Returned is the result from translating :param text into :param target_language and then into German. \n",
        "  \"\"\"\n",
        "  translator = deepl.Translator(deepl_auth_key) \n",
        "  result_eng = translator.translate_text(text, target_lang=target_language)\n",
        "  result_ger = translator.translate_text(result_eng.text, target_lang='DE')\n",
        "  return result_ger.text\n",
        "\n",
        "def oversample_dataframe(df):\n",
        "  \"\"\"\n",
        "  Accepts a dataframe and returns the dataframe with oversampled data. The function was written for the known dataset of the Goldstandard. \n",
        "  In detail, every Textstelle (from metaphors only) from the input dataframe is taken, translated into four languages (english, spanish, czech and polish) and back into German.\n",
        "  By this way, for each Textstelle from :param df, four new texts are generated and added to the output dataframe. \n",
        "\n",
        "  :param df: a pandas dataframe. \n",
        "  :return: a pandas dataframe. In the output dataframe, four columns have been added, in which the different back and forth translated German texts are. \n",
        "  \"\"\"\n",
        "  # Before the oversampling, the counts of unique rows in the input df and of rows which are metaphors are printed\n",
        "  print('Ausprägungen und Anzahl Werte für gold_standard_df vor Oversampling:', df['Metapher?'].value_counts())\n",
        "  print('Metaphern im gold_standard_df vor Oversampling', df['Metapher?'].value_counts().Metapher)\n",
        "\n",
        "  # To backup interim results, this counter is initialized\n",
        "  count = 1\n",
        "\n",
        "  # To keep count of successfully added translated metaphor texts, the following counter is initialized\n",
        "  count_successfully_added_metaphor_texts = 0\n",
        "\n",
        "  # Split the input dataframe into two dataframes, one containing only metaphors and one with only not metaphors\n",
        "  only_metaphor_df = df[(df['Metapher?'] == 'Metapher')]\n",
        "  no_metaphors_df = df[(df['Metapher?'] != 'Metapher')]\n",
        "\n",
        "  # To the dataframe containing only metaphors, add four columns where the newly generated texts can be inserted to\n",
        "  only_metaphor_df['Synonym (aus Englischem)'] = \"\"\n",
        "  only_metaphor_df['Synonym (aus Spanischem)'] = \"\"\n",
        "  only_metaphor_df['Synonym (aus Tchechischem)'] = \"\"\n",
        "  only_metaphor_df['Synonym (aus Polnischem)'] = \"\"\n",
        "  \n",
        "  # Loop over all rows in the dataframe containing only metaphors and translate the text back and forth and insert the German result in the correct dataframe cell\n",
        "  for index, row in only_metaphor_df.iterrows():\n",
        "    text = row['Textstelle']\n",
        "    row['Synonym (aus Englischem)'] = translate_into_target_language_and_back(text, 'EN-US')\n",
        "    row['Synonym (aus Spanischem)'] = translate_into_target_language_and_back(text, 'ES')\n",
        "    row['Synonym (aus Tchechischem)'] = translate_into_target_language_and_back(text, 'CS')\n",
        "    row['Synonym (aus Polnischem)'] = translate_into_target_language_and_back(text, 'PL')\n",
        "    count_successfully_added_metaphor_texts += 4\n",
        "    print('working, count:', count)\n",
        "\n",
        "    # Backup interim results of the dataframe as csv files every 'backup_oversampled_dataframe_after_rows' iterations\n",
        "    if (count % backup_oversampled_dataframe_after_rows == 0): \n",
        "      only_metaphor_df.to_csv('only_metaphor_df_four_languages_backup_iteration_' + str(count) + '.csv', index=False)\n",
        "\n",
        "    # Increase counter\n",
        "    count+=1\n",
        "\n",
        "  # After the for loop, the two dataframes only metaphor and not metaphors need to get concatenated again\n",
        "  oversampled_data_df = only_metaphor_df.append(no_metaphors_df)\n",
        "\n",
        "  # After the oversampling, print the counts of unique rows in the oversampled dataframe and of rows which are metaphors again to get an overview on the results of the data augmentation \n",
        "  print('Ausprägungen und Anzahl Werte für gold_standard_df nach Oversampling:', oversampled_data_df['Metapher?'].value_counts())\n",
        "  print('Metaphern im gold_standard_df nach Oversampling', oversampled_data_df['Metapher?'].value_counts().Metapher + count_successfully_added_metaphor_texts)\n",
        "\n",
        "  return oversampled_data_df\n",
        "\n",
        "# If the related parameter is set to true and a valid Deepl API Key is present, oversampling will be performed on the raw_df and this oversampled_data_df will be saved as .csv file\n",
        "#if (oversample_dataframe and deepl_auth_key != 'DEEPL_AUTH_KEY'):\n",
        "#  oversampled_data_df = oversample_dataframe(gold_standard_df)\n",
        "#  oversampled_data_df.to_csv('goldstandard_dataframe_oversampled.csv', index=False)\n",
        "\n",
        "# DAS IST DER AUFRUF ZUM OVERSAMPLEN; DER MUSS NOCH AN DER KORREKTEN STELLE EINGEBAUT WERDEN. \n"
      ],
      "metadata": {
        "id": "s2BeParsB8WN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DLDH_BERT_MetaphorDetection_Ternary.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}