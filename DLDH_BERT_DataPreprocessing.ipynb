{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLDH_BERT_DataPreprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ia3OfNYGSDjq",
        "-s4g-wdDR_Yw"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DatNguyen2084/DLDH-Metaphor-detection/blob/main/DLDH_BERT_DataPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gaGg4rtAawy"
      },
      "source": [
        "# Imports and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVmeL60UrIeI",
        "outputId": "f8574274-fdaf-420f-9d83-9be3aada0f27"
      },
      "source": [
        "!pip install PyDrive\n",
        "!pip install dkpro-cassis\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "import os.path\n",
        "import pandas as pd\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import numpy as np\n",
        "from cassis import *\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import re, pdb\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.12.10)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.26.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.35.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.9)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.55.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.17.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.2->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.3)\n",
            "Collecting dkpro-cassis\n",
            "  Downloading dkpro-cassis-0.7.0.tar.gz (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting lxml==4.7.*\n",
            "  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 9.3 MB/s \n",
            "\u001b[?25hCollecting attrs==21.2.*\n",
            "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers==2.4.* in /usr/local/lib/python3.7/dist-packages (from dkpro-cassis) (2.4.0)\n",
            "Collecting toposort==1.7\n",
            "  Downloading toposort-1.7-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: more-itertools==8.12.* in /usr/local/lib/python3.7/dist-packages (from dkpro-cassis) (8.12.0)\n",
            "Collecting deprecation==2.1.*\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: importlib_resources==5.4.* in /usr/local/lib/python3.7/dist-packages (from dkpro-cassis) (5.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation==2.1.*->dkpro-cassis) (21.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib_resources==5.4.*->dkpro-cassis) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deprecation==2.1.*->dkpro-cassis) (3.0.7)\n",
            "Building wheels for collected packages: dkpro-cassis\n",
            "  Building wheel for dkpro-cassis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dkpro-cassis: filename=dkpro_cassis-0.7.0-py3-none-any.whl size=74043 sha256=a895e10628158dc7adc4166f67e82bdc192ca7f80f2a3445280c67f6d2a8a934\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/3c/80/81baf39265b5b7edc634d37135db9d3954f925ef508892ef3f\n",
            "Successfully built dkpro-cassis\n",
            "Installing collected packages: toposort, lxml, deprecation, attrs, dkpro-cassis\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.4.0\n",
            "    Uninstalling attrs-21.4.0:\n",
            "      Successfully uninstalled attrs-21.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed attrs-21.2.0 deprecation-2.1.0 dkpro-cassis-0.7.0 lxml-4.7.1 toposort-1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "# The following data is needed: https://drive.google.com/drive/folders/159CN2MDaGLzuoiA7x--Qq5zEdPavFcpf?usp=sharing\n",
        "# Create a shortcut to your Drive (\"Drive-Verknüpfung hinzufügen\" zu \"Meine Ablage\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ROOT_PATH = '/content/drive/MyDrive/DLDH'\n",
        "DATA_PATH = ROOT_PATH + '/data'\n",
        "MODEL_PATH = ROOT_PATH + '/model'\n",
        "RESULTS_PATH = ROOT_PATH + '/results'"
      ],
      "metadata": {
        "id": "jaTcWQQYwJIl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6117aa-81c4-47ef-d700-8f92e0aa6a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EvBeOCkt-YJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ddb70e7-6006-47a6-df8f-f68748018f11"
      },
      "source": [
        "# Extracting the annotation data of phase 2 if necessary\n",
        "ANNOTATION_PATH = DATA_PATH + '/Annotationen - Stufe 2'\n",
        "\n",
        "if not os.path.exists(ANNOTATION_PATH):      # replace the file name with your file\n",
        "  zip_filepath = DATA_PATH + '/Annotationen - Stufe 2.zip'\n",
        "\n",
        "  !unzip \"$zip_filepath\" -d \"$DATA_PATH\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2.zip\n",
            "   creating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/\n",
            "   creating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/txt/\n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/txt/Schalk_Metaphern_GruppeBPT.txt  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/txt/Methner_Stufe2_pgg.txt  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/txt/Methner_Metaphern_GruppeBPT.txt  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/txt/Haecker_Stufe2_pgg.txt  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/txt/Haecker_Metaphern_GruppeBPT.txt  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/Häckel_Welträtsel_Stufe2_P.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/Darwin_Kap1_Stufe2_B.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/Häckel_Welträtsel_Stufe2_B.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/Häckel_Welträtsel_Stufe2_A.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/Darwin_Kap1_Stufe2_K.tsv  \n",
            "   creating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/\n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Weber_Stufe2_K.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Weber_Stufe2_P.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Weber_Stufe2_A.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_T_4.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_T_3.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_T_5.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Weber_Stufe2_B.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_T_2.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_P_3.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_P_2.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_P_5.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_pgg.txt  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_B_4.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_B_3.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Häckel_Welträtsel_Stufe2_K.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_P_4.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/TypeSystem.xml  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Michaelis_Stufe2_K.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_B_2.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Michaelis_Stufe2_P.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_B_1.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_B_5.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_T_1.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Schalk_Stufe2_P_1.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Michaelis_Stufe2_B.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Methner_Stufe2_P_2.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Methner_Stufe2_T_2.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Methner_Stufe2_T_1.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Methner_Stufe2_B_2.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Haecker_Stufe2_T_2.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Haecker_Stufe2_P_2.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Haecker_Stufe2_T.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Methner_Stufe2_B_1.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Haecker_Stufe2_P.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Haeckel_Lebenswunder_Stufe2_A.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Haeckel_Lebenswunder_Stufe2_K.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Haeckel_Lebenswunder_Stufe2_P.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Eleutheropulos_Stufe2_B.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Haecker_Stufe2_B.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Eleutheropulos_Stufe2_P.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Haeckel_Lebenswunder_Stufe2_B.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Haecker_Stufe2_B_2.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Methner_Stufe2_P_1.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Eleutheropulos_Stufe2_K.xmi  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/xmi/Ziegler_B.xmi  \n",
            "   creating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/\n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Woltmann_50 Sätze_B.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ziegler_50 Sätze_B.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Schallmeyer_Stufe2_Vergleich.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Woltmann_50 Sätze Woltmann_P.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ziegler_50 Sätze_P.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Schallmeyer_Stufe2_K.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Schallmeyer_Stufe2_A.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Schallmeyer_Stufe2_B.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ruppin_Stufe2_Vergleich.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ruppin_Stufe2_Negativfälle_K.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ruppin_Stufe2_Negativfälle_B.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ruppin_Stufe2_P.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ruppin_Stufe2_Negativfälle_P.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ruppin_Stufe2_K.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ruppin_Stufe2_B.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ruppin_Stufe2_gemeinsame Ergebnisse_positive Fälle_Einigkeit.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ruppin_Stufe2_A.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ruppin_Stufe2_gemeinsame Ergebnisse_negative Fälle_Uneinigkeit.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Matzat_Stufe2_P.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Matzat_Stufe2_Vergleich.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Matzat_Stufe2_K.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/RTPK_1916_paarweise_Instruvtions.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Matzat_Stufe2_B.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ziegler_50 Sätze_P.xlsx  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/RTPK_1916_paarweiser Vergleich_P.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/RTPK_1916_paarweise_K.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Blumenberg_Arbeit am Mythos_Gruppenergebnis und Vergleich mit pgg.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Blumenberg_Arbeit am Mythos_P.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/RTPK_1916_paarweise_B.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Blumenberg_ Arbeit am Mythos_T.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Blumenberg_Arbeit am Mythos_B.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Matzat_Stufe2_A.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ruppin_Stufe2_Negativfälle_A.tsv  \n",
            "  inflating: /content/drive/My Drive/DLDH/data/Annotationen - Stufe 2/tsv/Ruppin_Stufe2_Vergleich.xlsx  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia3OfNYGSDjq"
      },
      "source": [
        "# TSV Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf4UVnh_IS5G"
      },
      "source": [
        "def concat_string_from_rows(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    concatenate values of all rows together on columns 'Stelle', 'Fokus', 'Rahmen', \n",
        "    :param df: The given dataframe\n",
        "    :return re.sub: The concatenated values\n",
        "    \"\"\"  \n",
        "    result = ''\n",
        "    for s in df['Stelle'].values:\n",
        "        if result.endswith('-'):\n",
        "            result = result[:-1] + s\n",
        "        result = result + ' ' + s\n",
        "    return re.sub(' +', ' ', result)\n",
        "\n",
        "def concat_Fokus_Rahmen_from_rows(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    concatenate values of all rows together on columns 'Fokus', 'Rahmen', \n",
        "    :param df: The given dataframe\n",
        "    :return fokus: The fokus\n",
        "    :return rahmen: The rahmen\n",
        "    \"\"\"  \n",
        "    fokus = ''\n",
        "    rahmen = ''\n",
        "    for f in df['Fokus']:\n",
        "      if not pd.isnull(f) and (f not in fokus):\n",
        "          fokus = fokus + f + ','\n",
        "    for r in df['Rahmen']:\n",
        "      if not pd.isnull(r) and (r not in rahmen):\n",
        "          rahmen = rahmen + r + ','\n",
        "    # remove last ',' character\n",
        "    return fokus[:-1], rahmen[:-1]\n",
        "\n",
        "def get_sentence_dataframe(df, i):\n",
        "    \"\"\"\n",
        "    concatenate all sentences that were separated by newlines \n",
        "    :param df: The given dataframe\n",
        "    :param i: The index of the current row\n",
        "    :return tmp: The temporary text\n",
        "    :return i: The index of the current row after the operation\n",
        "    \"\"\"  \n",
        "    tmp = pd.DataFrame([], columns=df.columns.tolist())\n",
        "    while not pd.isnull(df.at[i, 'Stelle']):\n",
        "\n",
        "            tmp = tmp.append(df.loc[[i]])\n",
        "            i = i + 1\n",
        "            if i >= len(df):\n",
        "                return tmp, i\n",
        "    return tmp, i\n",
        "    \n",
        "def merge_rows_to_sentence(df: pd.DataFrame,filename):\n",
        "  \"\"\"\n",
        "  concatenates all sentences that were splitted into multiple rows in tsv\n",
        "  :param df: The given dataframe\n",
        "  :param filename: The filename of the tsv data\n",
        "  :return result: The dataframe with merged rows\n",
        "  \"\"\"    \n",
        "  columns = ['Textstelle', 'Metapher?','Fokus','Rahmen','Annotator', 'Filename']\n",
        "  result = pd.DataFrame([], columns=columns)\n",
        "  i = 0\n",
        "  while i < len(df):\n",
        "    #pdb.set_trace()\n",
        "    if pd.isnull(df.at[i, 'Stelle']):\n",
        "        # increase i until it meets onther empty row\n",
        "        i = i + 1\n",
        "    else:\n",
        "        tmp, i = get_sentence_dataframe(df, i)\n",
        "        if len(tmp) > 0:\n",
        "            s = concat_string_from_rows(tmp)\n",
        "            metapher = ''\n",
        "            fokus = ''\n",
        "            rahmen = ''\n",
        "            #print(\"s\", s)\n",
        "            if re.match(r'^Matzat|Schallmeyer', filename):\n",
        "              agreement = 0            \n",
        "              for annotator in ['P','K','A','B']:\n",
        "                if 'x' in tmp[annotator].unique():\n",
        "                  agreement +=1\n",
        "              if agreement > 2:\n",
        "                metapher = 'Metapher'\n",
        "            elif re.match(r'^Ruppin', filename):\n",
        "              if re.search('positive', filename):\n",
        "                metapher = 'Metapher'\n",
        "                fokus = tmp['Fokus'].unique()[0]\n",
        "                rahmen = tmp['Rahmen'].unique()[0]\n",
        "\n",
        "            new_line = pd.DataFrame([[s, metapher, fokus, rahmen, 'GoldStandard', filename ]], columns=columns)\n",
        "            result = result.append(new_line)            \n",
        "  return result\n",
        "\n",
        "def blumenberg(tsv,filename):\n",
        "  \"\"\"\n",
        "  special file handling for the text by Blumenberg\n",
        "  :param tsv: The tsv dataframe\n",
        "  :param filename: The filename of the tsv data\n",
        "  :return tsv: The dataframe including the text by Blumenberg\n",
        "  \"\"\"  \n",
        "  columns = ['Textstelle', 'Metapher?','Fokus','Rahmen','Annotator', 'Filename']\n",
        "\n",
        "  tsv = tsv[['Textstelle', 'Gruppe', 'Foki der Gruppe']]\n",
        "  tsv['Rahmen'] = ''\n",
        "  tsv['Annotator'] = 'GoldStandard'\n",
        "  tsv['Filename'] = filename\n",
        "  tsv.rename(columns={'Gruppe': 'Metapher?'}, inplace=True)\n",
        "  tsv.rename(columns={'Foki der Gruppe': 'Fokus'}, inplace=True)\n",
        "  tsv.loc[tsv['Metapher?'] == 'x', 'Metapher?'] = 'Metapher'\n",
        "  return tsv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some .tsv files should not be used due to duplicates \n",
        "# .tsv files to be excluded have to be written in the following array. Thereby these files will not be used while gathering data.\n",
        "excluding = [\"RTPK_1916_paarweise_Instruvtions.tsv\", \"RTPK_1916_paarweise_B.tsv\", \"RTPK_1916_paarweiser Vergleich_P.tsv\", \n",
        "             \"RTPK_1916_paarweise_K.tsv\", \"Matzat_Stufe2_Vergleich.tsv\", \"Schallmeyer_Stufe2_Vergleich.tsv\", \n",
        "             \"Blumenberg_Arbeit am Mythos_Gruppenergebnis und Vergleich mit pgg.tsv\", \"Ruppin_Stufe2_Vergleich.tsv\",\n",
        "             \"Ruppin_Stufe2_gemeinsame Ergebnisse_positive Fälle_Einigkeit.tsv\", \n",
        "             \"Ruppin_Stufe2_gemeinsame Ergebnisse_negative Fälle_Uneinigkeit.tsv\",\n",
        "             \"Ruppin_Stufe2_Negativfälle_A.tsv\", \"Ruppin_Stufe2_Negativfälle_K.tsv\", \"Ruppin_Stufe2_Negativfälle_P.tsv\", \n",
        "             \"Ruppin_Stufe2_Negativfälle_B.tsv\"]\n",
        "\n",
        "def open_tsv(path):\n",
        "    \"\"\"\n",
        "    opens all tsv files from a given path\n",
        "    :param path: The path of the tsv files\n",
        "    :return df: The dataframe containing the tsv data\n",
        "    \"\"\"  \n",
        "    annotator = None\n",
        "    df = pd.DataFrame()\n",
        "    for filename in os.listdir(path):\n",
        "        if filename.endswith('.tsv') and not filename in excluding:\n",
        "          # set annotator of the file based on the file's endings\n",
        "          if filename.endswith('_T.tsv'):\n",
        "            annotator = 'T'\n",
        "          elif filename.endswith('_B.tsv'):\n",
        "            annotator = 'B'\n",
        "          elif filename.endswith('_P.tsv'):\n",
        "            annotator = 'P'\n",
        "          elif filename.endswith('_A.tsv'):\n",
        "            annotator = 'A'\n",
        "          elif filename.endswith('_K.tsv'):\n",
        "            annotator = 'K'\n",
        "          else:\n",
        "            annotator = 'No Annotator'\n",
        "          tsv = pd.read_csv(os.path.join(path, filename), sep='\\t', header=0)\n",
        "          if re.match(r'^Matzat|Ruppin|Schallmeyer', filename):\n",
        "            print(f'merge rows for file {filename}')\n",
        "            tsv = merge_rows_to_sentence(tsv)\n",
        "            print(f'len: {len(tsv)}')\n",
        "          # add one column with the previously determined annotator\n",
        "          tsv['Annotator'] = annotator\n",
        "          # Some corrections of column names\n",
        "          if 'Stärkegrad (Á, B, C)' in tsv or 'Stärkegrad (0, 1, 2)' in tsv:\n",
        "            tsv.rename(columns={\"Stärkegrad (Á, B, C)\": \"Stärkegrad (A, B, C)\", \"Stärkegrad (0, 1, 2)\": \"Stärkegrad (A, B, C)\"}, inplace=True)\n",
        "            #tsv.loc['Stärkegrad (0, 1, 2)'] = (tsv['Stärkegrad (0, 1, 2)'] = 'A' 1990).astype(int)\n",
        "            tsv.loc[tsv['Stärkegrad (A, B, C)'] == '0', \"Stärkegrad (A, B, C)\"] = 'A'\n",
        "            tsv.loc[tsv['Stärkegrad (A, B, C)'] == '1', \"Stärkegrad (A, B, C)\"] = 'B'\n",
        "            tsv.loc[tsv['Stärkegrad (A, B, C)'] == '2', \"Stärkegrad (A, B, C)\"] = 'C'\n",
        "          if 'Metapher? ' in tsv or 'Metapher (ja=x; Nein = *leer*)' in tsv:\n",
        "            tsv.rename(columns={\"Metapher? \": \"Metapher?\", 'Metapher (ja=x; Nein = *leer*)': \"Metapher?\"}, inplace=True)\n",
        "          if 'Stelle' in tsv or 'Sätze' in tsv:\n",
        "            tsv.rename(columns={'Stelle': 'Textstelle', 'Sätze': 'Textstelle'}, inplace=True)\n",
        "          if 'Abschnitt' in tsv:\n",
        "            tsv.rename(columns={'Abschnitt': 'Seite'}, inplace=True)\n",
        "          if 'Fokus der Metapher' in tsv:\n",
        "            tsv.rename(columns={'Fokus der Metapher': 'Fokus'}, inplace=True)\n",
        "          if 'Theresa' in tsv:\n",
        "            tsv.rename(columns={'Theresa': 'Metapher?'}, inplace=True)          \n",
        "          if 'Begründung' in tsv:\n",
        "            tsv.rename(columns={'Begründung': 'Begründung/Kommentar'}, inplace=True)          \n",
        "\n",
        "\n",
        "          df = pd.concat([df,tsv], axis=0, ignore_index=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "tsv = open_tsv('/content/Annotationen - Stufe 2/tsv/')\n",
        "print(\"Column Names\")\n",
        "print(tsv.columns)\n",
        "\n",
        "print(\"Metaphor? values before cleanup\")\n",
        "print(tsv['Metapher?'].unique())\n",
        "\n",
        "# some more cleanup\n",
        "tsv.loc[tsv['Metapher?'] == 'X', 'Metapher?'] = 'Metapher'\n",
        "tsv.loc[tsv['Metapher?'] == 'x', 'Metapher?'] = 'Metapher'\n",
        "tsv.loc[tsv['Metapher?'] == 'Metapher', 'Metapher?'] = 'Metapher'\n",
        "tsv.loc[tsv['Metapher?'] == 'Metapher ', 'Metapher?'] = 'Metapher'\n",
        "tsv.fillna(value={'Metapher?': 'Nein'}, inplace=True)\n",
        "tsv.loc[tsv['Metapher?'] == 'nein', 'Metapher?'] = 'Nein'\n",
        "tsv.loc[tsv['Metapher?'] == 'nien', 'Metapher?'] = 'Nein'\n",
        "tsv.loc[tsv['Metapher?'] == 'nein ', 'Metapher?'] = 'Nein'\n",
        "tsv.drop(tsv[tsv['Metapher?'] == 'gleiches wie oben'].index, inplace=True)\n",
        "tsv.loc[tsv['Metapher?'] == '?', 'Metapher?'] = 'Unklar'\n",
        "tsv.loc[tsv['Metapher?'] == 'unklar', 'Metapher?'] = 'Unklar'\n",
        "tsv.loc[tsv['Metapher?'] == 'Metapher/Grenzfall', 'Metapher?'] = 'Grenzfall'\n",
        "tsv.loc[tsv['Metapher?'] == 'ungeklärter Grenzfall', 'Metapher?'] = 'Grenzfall'\n",
        "\n",
        "print(\"Metaphor? values after cleanup\")\n",
        "print(tsv['Metapher?'].unique())\n",
        "\n",
        "print(len(tsv))"
      ],
      "metadata": {
        "id": "KTT-aynOYcEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s4g-wdDR_Yw"
      },
      "source": [
        "#XMI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "iZWreSkJj2C0",
        "outputId": "64979f49-5fa3-40ac-857c-f4c9e488d0bc"
      },
      "source": [
        "def get_dataframe_from_xmi(path,typesystem):\n",
        "  \"\"\"\n",
        "  creates a pandas dataframe from a xmi file\n",
        "  :param path: The path of the xmi file\n",
        "  :param typesystem: The typesystem of the xmi file\n",
        "  :return df: The dataframe containing the xmi data\n",
        "  \"\"\"  \n",
        "  with open(typesystem, 'rb') as f:\n",
        "    typesystem = load_typesystem(f)\n",
        "\n",
        "  column_names = [\"Textstelle\", \"Metapher?\", \"Fokus\", \"Rahmen\", \"Stärkegrad (A, B, C)\", \"Annotator\", \"Filename\"]\n",
        "\n",
        "  df = pd.DataFrame(columns = column_names)\n",
        "  for filename in os.listdir(path):\n",
        "    with open(os.path.join(path, filename), 'rb') as f:\n",
        "      if \"Stufe2\" in filename and filename.endswith('.xmi'):\n",
        "\n",
        "        # getting annotator\n",
        "        annotator = get_annotator(os.path.splitext(filename)[0])\n",
        "        \n",
        "        cas = load_cas_from_xmi(f, typesystem=typesystem)\n",
        "        # getting all sentences\n",
        "        for i, sentence in enumerate(cas.select(\"de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence\")):\n",
        "          sentence_text = sentence.get_covered_text()\n",
        "\n",
        "          # getting all focuses\n",
        "          fokus_list = cas.select_covered('webanno.custom.Fokus', sentence)\n",
        "          if len(fokus_list) > 0:\n",
        "            for fokus in fokus_list:\n",
        "              fokus_text = fokus.get_covered_text()\n",
        "              # getting the Rahmen for the Fokus via the FokusRahmenLink\n",
        "              if len(fokus['Rahmen']['elements']) > 0:\n",
        "                rahmen = fokus['Rahmen']['elements'][0]['target']\n",
        "                rahmen_text = rahmen.get_covered_text()\n",
        "              # apparently, there are Fokus annotations without a specified Rahmen, this would be the place to exclude them\n",
        "              else:\n",
        "                rahmen_text = ''\n",
        "\n",
        "              # getting the Score_ABC\n",
        "              score = fokus['Score_ABC']\n",
        "\n",
        "              df_entry = pd.DataFrame([[sentence_text, 'Metapher', fokus_text, rahmen_text, score, annotator, filename]], columns=column_names)\n",
        "              df = pd.concat([df,df_entry], axis=0, ignore_index=True)\n",
        "          else:\n",
        "            df_entry = pd.DataFrame([[sentence_text, 'Nein', np.NaN, np.NaN, np.NaN, annotator, filename]], columns=column_names)\n",
        "            df = pd.concat([df,df_entry], axis=0, ignore_index=True)\n",
        "  return df\n",
        "   \n",
        "def get_annotator(filename):\n",
        "  \"\"\"\n",
        "  returns the annotator of a file\n",
        "  :param filename: The name of the file\n",
        "  :return annotator: The annotator who annotated this file\n",
        "  \"\"\"  \n",
        "  annotator = None\n",
        "  if filename.endswith('T') or filename.endswith('T_1') or filename.endswith('T_2') or filename.endswith('T_3') or filename.endswith('T_4') or filename.endswith('T_5'):\n",
        "    annotator = 'T'\n",
        "  elif filename.endswith('P') or filename.endswith('P_1') or filename.endswith('P_2') or filename.endswith('P_3') or filename.endswith('P_4') or filename.endswith('P_5'):\n",
        "    annotator = 'P'\n",
        "  elif filename.endswith('B') or filename.endswith('B_1') or filename.endswith('B_2') or filename.endswith('B_3') or filename.endswith('B_4') or filename.endswith('B_5'):\n",
        "    annotator = 'B'\n",
        "  elif filename.endswith('A') or filename.endswith('A_1') or filename.endswith('A_2') or filename.endswith('A_3') or filename.endswith('A_4') or filename.endswith('A_5'):\n",
        "    annotator = 'A'\n",
        "  elif filename.endswith('K') or filename.endswith('K_1') or filename.endswith('K_2') or filename.endswith('K_3') or filename.endswith('K_4') or filename.endswith('K_5'):\n",
        "    annotator = 'K'\n",
        "  else:\n",
        "    annotator = 'No Annotator'\n",
        "  return annotator\n",
        "\n",
        "file_path=\"/content/Annotationen - Stufe 2/xmi/\"\n",
        "type_system=os.path.join(file_path,\"TypeSystem.xml\")\n",
        "\n",
        "xmi = get_dataframe_from_xmi(file_path, type_system)\n",
        "print(len(xmi))\n",
        "xmi.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "765\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ddd56408-6dc3-430f-baa8-c51dff639aa3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Textstelle</th>\n",
              "      <th>Metapher?</th>\n",
              "      <th>Fokus</th>\n",
              "      <th>Rahmen</th>\n",
              "      <th>Stärkegrad (A, B, C)</th>\n",
              "      <th>Annotator</th>\n",
              "      <th>Filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Das Denken wird ihm schwer, er strengt seinen ...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>überwuchern</td>\n",
              "      <td>daß seine Einbildungskraft seinen Verstand und...</td>\n",
              "      <td>C</td>\n",
              "      <td>P</td>\n",
              "      <td>Schalk_Stufe2_P_1.xmi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Unter allen natürlichen Produkten eines Landes...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>versteinerte</td>\n",
              "      <td>Sonnenstrahlen</td>\n",
              "      <td>C</td>\n",
              "      <td>P</td>\n",
              "      <td>Schalk_Stufe2_P_1.xmi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Aus der ganzen Darstellung erkennt man, daß de...</td>\n",
              "      <td>Nein</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>P</td>\n",
              "      <td>Schalk_Stufe2_P_1.xmi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Da die organische Natur aus der anorganischen ...</td>\n",
              "      <td>Nein</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>P</td>\n",
              "      <td>Schalk_Stufe2_P_1.xmi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vielleicht würden alle etwas mehr wissen, wenn...</td>\n",
              "      <td>Nein</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>P</td>\n",
              "      <td>Schalk_Stufe2_P_1.xmi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>So wird sich wiederholen, was uns die Geschich...</td>\n",
              "      <td>Nein</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>P</td>\n",
              "      <td>Schalk_Stufe2_P_1.xmi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Die Materie schafft die Welten mit allen den b...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>die Verkehrsstraße zwischen den Welten</td>\n",
              "      <td>der Äther ist</td>\n",
              "      <td>B</td>\n",
              "      <td>P</td>\n",
              "      <td>Schalk_Stufe2_P_1.xmi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Man kann kaum begreifen, wie irgend jemand sic...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>versteinerter</td>\n",
              "      <td>Sonnenstrahlen</td>\n",
              "      <td>C</td>\n",
              "      <td>P</td>\n",
              "      <td>Schalk_Stufe2_P_1.xmi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Das Haus, infolge seiner größeren Benutzung, e...</td>\n",
              "      <td>Nein</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>P</td>\n",
              "      <td>Schalk_Stufe2_P_1.xmi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Auch bei Tieren, besonders bei gesellig lebend...</td>\n",
              "      <td>Nein</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>P</td>\n",
              "      <td>Schalk_Stufe2_P_1.xmi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddd56408-6dc3-430f-baa8-c51dff639aa3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ddd56408-6dc3-430f-baa8-c51dff639aa3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ddd56408-6dc3-430f-baa8-c51dff639aa3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          Textstelle  ...               Filename\n",
              "0  Das Denken wird ihm schwer, er strengt seinen ...  ...  Schalk_Stufe2_P_1.xmi\n",
              "1  Unter allen natürlichen Produkten eines Landes...  ...  Schalk_Stufe2_P_1.xmi\n",
              "2  Aus der ganzen Darstellung erkennt man, daß de...  ...  Schalk_Stufe2_P_1.xmi\n",
              "3  Da die organische Natur aus der anorganischen ...  ...  Schalk_Stufe2_P_1.xmi\n",
              "4  Vielleicht würden alle etwas mehr wissen, wenn...  ...  Schalk_Stufe2_P_1.xmi\n",
              "5  So wird sich wiederholen, was uns die Geschich...  ...  Schalk_Stufe2_P_1.xmi\n",
              "6  Die Materie schafft die Welten mit allen den b...  ...  Schalk_Stufe2_P_1.xmi\n",
              "7  Man kann kaum begreifen, wie irgend jemand sic...  ...  Schalk_Stufe2_P_1.xmi\n",
              "8  Das Haus, infolge seiner größeren Benutzung, e...  ...  Schalk_Stufe2_P_1.xmi\n",
              "9  Auch bei Tieren, besonders bei gesellig lebend...  ...  Schalk_Stufe2_P_1.xmi\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combine xmi and tsv data\n",
        "df = pd.concat([tsv,xmi], axis=0, ignore_index=True)\n",
        "\n",
        "# save gold standard as csv\n",
        "df.to_csv(DATA_PATH + '/Annotationen-Stufe-2.csv')"
      ],
      "metadata": {
        "id": "VpE5bwtBZLUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gold Standard"
      ],
      "metadata": {
        "id": "A1ObwVF7ZsbK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5TrOORISGXO",
        "outputId": "77308661-af02-4dfc-e4b5-1c233bad64c8"
      },
      "source": [
        "# The following tsv files contain a gold standard discussed by the annotators\n",
        "including = [\"Blumenberg_Arbeit am Mythos_Gruppenergebnis und Vergleich mit pgg.tsv\", \"Matzat_Stufe2_Vergleich.tsv\", \"Schallmeyer_Stufe2_Vergleich.tsv\",\n",
        "             \"Ruppin_Stufe2_gemeinsame Ergebnisse_negative Fälle_Uneinigkeit.tsv\", \"Ruppin_Stufe2_gemeinsame Ergebnisse_positive Fälle_Einigkeit.tsv\"]\n",
        "\n",
        "\n",
        "def open_tsv_gold_standard(path):\n",
        "    \"\"\"\n",
        "    opens all tsv files from a given path for the gold standard\n",
        "    :param path: The path of the tsv files\n",
        "    :return df: The dataframe containing the tsv data\n",
        "    \"\"\"  \n",
        "    annotator = None\n",
        "    df = pd.DataFrame()\n",
        "    for filename in os.listdir(path):\n",
        "        if filename.endswith('.tsv') and filename in including:\n",
        "          # set annotator of the file based on the file's endings\n",
        "          annotator = 'GoldStandard'\n",
        "          tsv = pd.read_csv(os.path.join(path, filename), sep='\\t', header=0)\n",
        "\n",
        "          if re.match(r'^Matzat|Schallmeyer|Ruppin', filename):\n",
        "            print(f'merge rows for file {filename}')\n",
        "            tsv = merge_rows_to_sentence(tsv,filename)\n",
        "          elif re.match(r'^Blumenberg', filename):\n",
        "            tsv = blumenberg(tsv,filename)\n",
        "\n",
        "          print(f'len: {len(tsv)}')\n",
        "          # add one column with the previously determined annotator\n",
        "          tsv['Annotator'] = annotator\n",
        "          tsv['Filename'] = filename\n",
        "          # Some corrections of column names\n",
        "          if 'Stärkegrad (Á, B, C)' in tsv or 'Stärkegrad (0, 1, 2)' in tsv:\n",
        "            tsv.rename(columns={\"Stärkegrad (Á, B, C)\": \"Stärkegrad (A, B, C)\", \"Stärkegrad (0, 1, 2)\": \"Stärkegrad (A, B, C)\"}, inplace=True)\n",
        "            #tsv.loc['Stärkegrad (0, 1, 2)'] = (tsv['Stärkegrad (0, 1, 2)'] = 'A' 1990).astype(int)\n",
        "            tsv.loc[tsv['Stärkegrad (A, B, C)'] == '0', \"Stärkegrad (A, B, C)\"] = 'A'\n",
        "            tsv.loc[tsv['Stärkegrad (A, B, C)'] == '1', \"Stärkegrad (A, B, C)\"] = 'B'\n",
        "            tsv.loc[tsv['Stärkegrad (A, B, C)'] == '2', \"Stärkegrad (A, B, C)\"] = 'C'\n",
        "          if 'Metapher? ' in tsv or 'Metapher (ja=x; Nein = *leer*)' in tsv:\n",
        "            tsv.rename(columns={\"Metapher? \": \"Metapher?\", 'Metapher (ja=x; Nein = *leer*)': \"Metapher?\"}, inplace=True)\n",
        "          if 'Stelle' in tsv or 'Sätze' in tsv:\n",
        "            tsv.rename(columns={'Stelle': 'Textstelle', 'Sätze': 'Textstelle'}, inplace=True)\n",
        "          if 'Abschnitt' in tsv:\n",
        "            tsv.rename(columns={'Abschnitt': 'Seite'}, inplace=True)\n",
        "          if 'Fokus der Metapher' in tsv:\n",
        "            tsv.rename(columns={'Fokus der Metapher': 'Fokus'}, inplace=True)\n",
        "          if 'Theresa' in tsv:\n",
        "            tsv.rename(columns={'Theresa': 'Metapher?'}, inplace=True)          \n",
        "          if 'Begründung' in tsv:\n",
        "            tsv.rename(columns={'Begründung': 'Begründung/Kommentar'}, inplace=True)          \n",
        "\n",
        "\n",
        "          df = pd.concat([df,tsv], axis=0, ignore_index=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "tsv_gold_standard = open_tsv_gold_standard('/content/Annotationen - Stufe 2/tsv/')\n",
        "print(\"Column Names\")\n",
        "print(tsv.columns)\n",
        "\n",
        "print(\"Metaphor? values before cleanup\")\n",
        "print(tsv['Metapher?'].unique())\n",
        "\n",
        "# some more cleanup\n",
        "tsv_gold_standard = tsv_gold_standard[tsv_gold_standard['Textstelle'].notnull()]\n",
        "tsv_gold_standard.loc[tsv_gold_standard['Metapher?'] == 'X', 'Metapher?'] = 'Metapher'\n",
        "tsv_gold_standard.loc[tsv_gold_standard['Metapher?'] == 'x', 'Metapher?'] = 'Metapher'\n",
        "tsv_gold_standard.loc[tsv_gold_standard['Metapher?'] == 'Metapher', 'Metapher?'] = 'Metapher'\n",
        "tsv_gold_standard.loc[tsv_gold_standard['Metapher?'] == 'Metapher ', 'Metapher?'] = 'Metapher'\n",
        "tsv_gold_standard.fillna(value={'Metapher?': 'Metaphernkandidat'}, inplace=True)\n",
        "tsv_gold_standard.loc[tsv_gold_standard['Metapher?'] == 'nein', 'Metapher?'] = 'Metaphernkandidat'\n",
        "tsv_gold_standard.loc[tsv_gold_standard['Metapher?'] == 'nien', 'Metapher?'] = 'Metaphernkandidat'\n",
        "tsv_gold_standard.loc[tsv_gold_standard['Metapher?'] == 'nein ', 'Metapher?'] = 'Metaphernkandidat'\n",
        "tsv_gold_standard.loc[tsv_gold_standard['Metapher?'] == '', 'Metapher?'] = 'Metaphernkandidat'\n",
        "tsv_gold_standard.drop(tsv_gold_standard[tsv_gold_standard['Metapher?'] == 'gleiches wie oben'].index, inplace=True)\n",
        "tsv_gold_standard.loc[tsv_gold_standard['Metapher?'] == '?', 'Metapher?'] = 'Unklar'\n",
        "tsv_gold_standard.loc[tsv_gold_standard['Metapher?'] == 'unklar', 'Metapher?'] = 'Unklar'\n",
        "tsv_gold_standard.loc[tsv_gold_standard['Metapher?'] == 'Metapher/Grenzfall', 'Metapher?'] = 'Grenzfall'\n",
        "tsv_gold_standard.loc[tsv_gold_standard['Metapher?'] == 'ungeklärter Grenzfall', 'Metapher?'] = 'Grenzfall'\n",
        "\n",
        "print(\"Metaphor? values after cleanup\")\n",
        "print(tsv_gold_standard['Metapher?'].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merge rows for file Matzat_Stufe2_Vergleich.tsv\n",
            "len: 101\n",
            "merge rows for file Ruppin_Stufe2_gemeinsame Ergebnisse_positive Fälle_Einigkeit.tsv\n",
            "len: 35\n",
            "merge rows for file Schallmeyer_Stufe2_Vergleich.tsv\n",
            "len: 145\n",
            "merge rows for file Ruppin_Stufe2_gemeinsame Ergebnisse_negative Fälle_Uneinigkeit.tsv\n",
            "len: 30\n",
            "len: 112\n",
            "Column Names\n",
            "Index(['Textstelle', 'Metapher?', 'Fokus', 'Rahmen', 'Annotator', 'Filename'], dtype='object')\n",
            "Metaphor? values before cleanup\n",
            "['Metapher' '' nan]\n",
            "Metaphor? values after cleanup\n",
            "['Metapher' 'Metaphernkandidat']\n",
            "423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:83: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:87: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def xmi_gold_standard(xmi):\n",
        "  \"\"\"\n",
        "  Generates a gold standard from given xmi data\n",
        "  :param xmi: The xmi dataframe\n",
        "  :return result: The dataframe containing the gold standard\n",
        "  \"\"\"  \n",
        "  textstellen = xmi['Textstelle'].unique()\n",
        "  columns = ['Textstelle', 'Metapher?','Fokus','Rahmen','Annotator', 'Filename']\n",
        "  result = pd.DataFrame([], columns=columns)\n",
        "  for stelle in textstellen:\n",
        "    metapher = 'Metaphernkandidat'\n",
        "    fokus = ''\n",
        "    rahmen = ''\n",
        "    tmp = xmi[xmi['Textstelle'] == stelle]\n",
        "    entries = len(tmp)\n",
        "    if entries < 2:\n",
        "      print(stelle)\n",
        "    # calculating the annotator agreement\n",
        "    agreement = len(tmp[tmp['Metapher?'] == 'Metapher'])\n",
        "    # accepting as metaphor if agreement is higher than 0.5\n",
        "    if agreement / entries > 0.5:\n",
        "      metapher = 'Metapher'\n",
        "      fokus = tmp['Fokus'].dropna().tolist()\n",
        "      rahmen = tmp['Rahmen'].dropna().tolist()\n",
        "    filename = tmp['Filename'].tolist()\n",
        "\n",
        "    new_line = pd.DataFrame([[stelle, metapher, fokus, rahmen, 'GoldStandard', filename]], columns=columns)\n",
        "    result = result.append(new_line)\n",
        "\n",
        "  return result\n",
        "\n",
        "xmi_gold_standard = xmi_gold_standard(xmi)\n",
        "\n",
        "xmi_gold_standard.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "g9ZhKc9a7avF",
        "outputId": "e544f908-5237-48bb-843d-04ec2fd499e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c2f122a7-664f-43e5-b25c-445798020c3e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Textstelle</th>\n",
              "      <th>Metapher?</th>\n",
              "      <th>Fokus</th>\n",
              "      <th>Rahmen</th>\n",
              "      <th>Annotator</th>\n",
              "      <th>Filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Zunächst natürlich: Kenntnisse über die Techni...</td>\n",
              "      <td>Metaphernkandidat</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>[Weber_Stufe2_K.xmi, Weber_Stufe2_P.xmi, Weber...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Denn er erhascht von dem, was das Leben des Ge...</td>\n",
              "      <td>Metaphernkandidat</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>[Weber_Stufe2_K.xmi, Weber_Stufe2_P.xmi, Weber...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Das aber bedeutet: die Entzauberung der Welt.</td>\n",
              "      <td>Metaphernkandidat</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>[Weber_Stufe2_K.xmi, Weber_Stufe2_P.xmi, Weber...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Der Schimmer einer hohen sittlichen Idee aber ...</td>\n",
              "      <td>Metaphernkandidat</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>[Methner_Stufe2_T_2.xmi, Methner_Stufe2_B_2.xm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22\\tWie ist die kunstreich zusammengesetzte Ma...</td>\n",
              "      <td>Metaphernkandidat</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>[Haeckel_Lebenswunder_Stufe2_B.xmi, Haeckel_Le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wenn wir von dem schlechten Worte »Rechtsphilo...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>[schwindsüchtig, schwindsüchtig ist]</td>\n",
              "      <td>[eine Philosophie, daß eine Philosophie]</td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>[Eleutheropulos_Stufe2_K.xmi, Eleutheropulos_S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[8]: So band er das Geschlecht von heute an da...</td>\n",
              "      <td>Metapher</td>\n",
              "      <td>[der Zukunft, der Vergangenheit2, starrt in da...</td>\n",
              "      <td>[in die Morgenröte, starrt in das Dunkel, der ...</td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>[Michaelis_Stufe2_P.xmi, Michaelis_Stufe2_P.xm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wenn man gewöhnlich mit Aristoteles, Pol. I, 6...</td>\n",
              "      <td>Metaphernkandidat</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>[Eleutheropulos_Stufe2_K.xmi, Eleutheropulos_S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Da die organische Natur aus der anorganischen ...</td>\n",
              "      <td>Metaphernkandidat</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>[Schalk_Stufe2_P_1.xmi, Schalk_Stufe2_B_1.xmi,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Unter solchen Umständen ist es natürlich, daß ...</td>\n",
              "      <td>Metaphernkandidat</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>GoldStandard</td>\n",
              "      <td>[Schalk_Stufe2_P_4.xmi, Schalk_Stufe2_T_4.xmi,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2f122a7-664f-43e5-b25c-445798020c3e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2f122a7-664f-43e5-b25c-445798020c3e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2f122a7-664f-43e5-b25c-445798020c3e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          Textstelle  ...                                           Filename\n",
              "0  Zunächst natürlich: Kenntnisse über die Techni...  ...  [Weber_Stufe2_K.xmi, Weber_Stufe2_P.xmi, Weber...\n",
              "0  Denn er erhascht von dem, was das Leben des Ge...  ...  [Weber_Stufe2_K.xmi, Weber_Stufe2_P.xmi, Weber...\n",
              "0      Das aber bedeutet: die Entzauberung der Welt.  ...  [Weber_Stufe2_K.xmi, Weber_Stufe2_P.xmi, Weber...\n",
              "0  Der Schimmer einer hohen sittlichen Idee aber ...  ...  [Methner_Stufe2_T_2.xmi, Methner_Stufe2_B_2.xm...\n",
              "0  22\\tWie ist die kunstreich zusammengesetzte Ma...  ...  [Haeckel_Lebenswunder_Stufe2_B.xmi, Haeckel_Le...\n",
              "0  wenn wir von dem schlechten Worte »Rechtsphilo...  ...  [Eleutheropulos_Stufe2_K.xmi, Eleutheropulos_S...\n",
              "0  [8]: So band er das Geschlecht von heute an da...  ...  [Michaelis_Stufe2_P.xmi, Michaelis_Stufe2_P.xm...\n",
              "0  Wenn man gewöhnlich mit Aristoteles, Pol. I, 6...  ...  [Eleutheropulos_Stufe2_K.xmi, Eleutheropulos_S...\n",
              "0  Da die organische Natur aus der anorganischen ...  ...  [Schalk_Stufe2_P_1.xmi, Schalk_Stufe2_B_1.xmi,...\n",
              "0  Unter solchen Umständen ist es natürlich, daß ...  ...  [Schalk_Stufe2_P_4.xmi, Schalk_Stufe2_T_4.xmi,...\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jTTBaMtTp4_",
        "outputId": "953adb43-da59-4019-b3fe-2c8cb778e195"
      },
      "source": [
        "# combine xmi and tsv gold standards\n",
        "df_gold_standard = pd.concat([tsv_gold_standard,xmi_gold_standard], axis=0, ignore_index=True)\n",
        "\n",
        "# save gold standard as csv\n",
        "df_gold_standard.to_csv(DATA_PATH + '/Annotationen-Stufe-2-GoldStandard.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "658"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}