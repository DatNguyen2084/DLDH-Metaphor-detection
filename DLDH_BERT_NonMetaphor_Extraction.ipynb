{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DatNguyen2084/DLDH-Metaphor-detection/blob/main/DLDH_BERT_NonMetaphor_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gaGg4rtAawy"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVmeL60UrIeI",
        "outputId": "d3c23259-1acc-4288-8442-9951f4744408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.12.8)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.26.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.35.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.54.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (21.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.17.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.9)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2021.10.8)\n",
            "Collecting dkpro-cassis\n",
            "  Downloading dkpro-cassis-0.7.0.tar.gz (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting lxml==4.7.*\n",
            "  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 16.1 MB/s \n",
            "\u001b[?25hCollecting attrs==21.2.*\n",
            "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers==2.4.* in /usr/local/lib/python3.7/dist-packages (from dkpro-cassis) (2.4.0)\n",
            "Collecting toposort==1.7\n",
            "  Downloading toposort-1.7-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: more-itertools==8.12.* in /usr/local/lib/python3.7/dist-packages (from dkpro-cassis) (8.12.0)\n",
            "Collecting deprecation==2.1.*\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: importlib_resources==5.4.* in /usr/local/lib/python3.7/dist-packages (from dkpro-cassis) (5.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation==2.1.*->dkpro-cassis) (21.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib_resources==5.4.*->dkpro-cassis) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deprecation==2.1.*->dkpro-cassis) (3.0.6)\n",
            "Building wheels for collected packages: dkpro-cassis\n",
            "  Building wheel for dkpro-cassis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dkpro-cassis: filename=dkpro_cassis-0.7.0-py3-none-any.whl size=74043 sha256=595bd622c8a69feca2257cdb958ebf0dcf0cde419a95dbd50af6e1676bf5615a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/3c/80/81baf39265b5b7edc634d37135db9d3954f925ef508892ef3f\n",
            "Successfully built dkpro-cassis\n",
            "Installing collected packages: toposort, lxml, deprecation, attrs, dkpro-cassis\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.4.0\n",
            "    Uninstalling attrs-21.4.0:\n",
            "      Successfully uninstalled attrs-21.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed attrs-21.2.0 deprecation-2.1.0 dkpro-cassis-0.7.0 lxml-4.7.1 toposort-1.7\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install PyDrive\n",
        "!pip install dkpro-cassis\n",
        "!pip install fuzzywuzzy\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "import os.path\n",
        "import pandas as pd\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import numpy as np\n",
        "from cassis import *\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "from fuzzywuzzy import fuzz\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "Hlx6R7DEvmjA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAU1ujC-aAd7"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "# The following data is needed: https://drive.google.com/drive/folders/159CN2MDaGLzuoiA7x--Qq5zEdPavFcpf?usp=sharing\n",
        "# Create a shortcut to your Drive (\"Drive-Verknüpfung hinzufügen\" zu \"Meine Ablage\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ROOT_PATH = '/content/drive/MyDrive/DLDH'\n",
        "DATA_PATH = '/data'\n",
        "TEXT_PATH = '/original_texts'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the gold standard to compare to\n",
        "gold_standard_df = pd.read_csv(ROOT_PATH + DATA_PATH + '/Annotationen-Stufe-2-GoldStandard.csv')"
      ],
      "metadata": {
        "id": "yv4w0U1vvvO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y5TrOORISGXO",
        "outputId": "9651f9b6-385b-4617-8c22-52c8b065203d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nus1_2_matzat_bereinigt.txt\n",
            "Current dataframe size: 100\n",
            "Current dataframe size: 200\n",
            "Current dataframe size: 300\n",
            "Current dataframe size: 400\n",
            "Current dataframe size: 500\n",
            "len 500\n",
            "Saved Dataframe as csv.\n",
            "nus2_2_ruppin_bereinigt.txt\n",
            "Current dataframe size: 600\n",
            "Current dataframe size: 700\n",
            "Current dataframe size: 800\n",
            "Current dataframe size: 900\n",
            "Current dataframe size: 1000\n",
            "len 1000\n",
            "Saved Dataframe as csv.\n",
            "nus3_2_schallmeyer_bereinigt.txt\n",
            "Current dataframe size: 1100\n",
            "Current dataframe size: 1200\n",
            "Current dataframe size: 1300\n",
            "Current dataframe size: 1400\n",
            "Current dataframe size: 1500\n",
            "len 1500\n",
            "Saved Dataframe as csv.\n",
            "nus6_2_Eleutheropulos_bereinigt.txt\n",
            "Current dataframe size: 1600\n",
            "Current dataframe size: 1700\n",
            "Current dataframe size: 1800\n",
            "Current dataframe size: 1900\n",
            "Current dataframe size: 2000\n",
            "len 2000\n",
            "Saved Dataframe as csv.\n",
            "nus9_2_Haecker_bereinigt.txt\n",
            "Current dataframe size: 2100\n",
            "Current dataframe size: 2200\n",
            "Current dataframe size: 2300\n",
            "Current dataframe size: 2400\n",
            "Current dataframe size: 2500\n",
            "len 2500\n",
            "Saved Dataframe as csv.\n",
            "nus8_2_Methner_bereinigt.txt\n",
            "Current dataframe size: 2600\n",
            "Current dataframe size: 2700\n",
            "Current dataframe size: 2800\n",
            "Current dataframe size: 2900\n",
            "Current dataframe size: 3000\n",
            "len 3000\n",
            "Saved Dataframe as csv.\n",
            "nus5_2_Michaelis_bereinigt.txt\n",
            "Current dataframe size: 3100\n",
            "Current dataframe size: 3200\n",
            "Current dataframe size: 3300\n",
            "Current dataframe size: 3400\n",
            "Current dataframe size: 3500\n",
            "len 3500\n",
            "Saved Dataframe as csv.\n",
            "nus7_2_Schalk_bereinigt.txt\n",
            "Current dataframe size: 3600\n",
            "Current dataframe size: 3700\n",
            "Current dataframe size: 3800\n",
            "Current dataframe size: 3900\n",
            "Current dataframe size: 4000\n",
            "len 4000\n",
            "Saved Dataframe as csv.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d7301e53-9351-4bc2-bc80-5e0cfcde91b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Annotator</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Fokus</th>\n",
              "      <th>Metapher?</th>\n",
              "      <th>Rahmen</th>\n",
              "      <th>Textstelle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1669</th>\n",
              "      <td>X</td>\n",
              "      <td>nus6_2_Eleutheropulos_bereinigt.txt</td>\n",
              "      <td></td>\n",
              "      <td>Nein</td>\n",
              "      <td></td>\n",
              "      <td>Mit der auf breitere Basis gestellten Induktio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3635</th>\n",
              "      <td>X</td>\n",
              "      <td>nus7_2_Schalk_bereinigt.txt</td>\n",
              "      <td></td>\n",
              "      <td>Nein</td>\n",
              "      <td></td>\n",
              "      <td>Alle diese Leute, welche von Generation zu Gen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>X</td>\n",
              "      <td>nus1_2_matzat_bereinigt.txt</td>\n",
              "      <td></td>\n",
              "      <td>Nein</td>\n",
              "      <td></td>\n",
              "      <td>Wenn irgend ein Verhältnis objektiver Förderun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1050</th>\n",
              "      <td>X</td>\n",
              "      <td>nus3_2_schallmeyer_bereinigt.txt</td>\n",
              "      <td></td>\n",
              "      <td>Nein</td>\n",
              "      <td></td>\n",
              "      <td>Denn je höher die Zivilisation steigt, desto m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>X</td>\n",
              "      <td>nus2_2_ruppin_bereinigt.txt</td>\n",
              "      <td></td>\n",
              "      <td>Nein</td>\n",
              "      <td></td>\n",
              "      <td>Mit Recht bemerkt aber Tylor1), 1) Introductio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3828</th>\n",
              "      <td>X</td>\n",
              "      <td>nus7_2_Schalk_bereinigt.txt</td>\n",
              "      <td></td>\n",
              "      <td>Nein</td>\n",
              "      <td></td>\n",
              "      <td>Sehr bald wurde sie käuf- lich durch Versprech...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1240</th>\n",
              "      <td>X</td>\n",
              "      <td>nus3_2_schallmeyer_bereinigt.txt</td>\n",
              "      <td></td>\n",
              "      <td>Nein</td>\n",
              "      <td></td>\n",
              "      <td>Dafür kann die Eizelle auf Beweglichkeit verzi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1763</th>\n",
              "      <td>X</td>\n",
              "      <td>nus6_2_Eleutheropulos_bereinigt.txt</td>\n",
              "      <td></td>\n",
              "      <td>Nein</td>\n",
              "      <td></td>\n",
              "      <td>Prinzipiell tritt er uns in zwei Formen entgeg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1948</th>\n",
              "      <td>X</td>\n",
              "      <td>nus6_2_Eleutheropulos_bereinigt.txt</td>\n",
              "      <td></td>\n",
              "      <td>Nein</td>\n",
              "      <td></td>\n",
              "      <td>Erst jetzt sind uns aber auch die Erscheinunge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1793</th>\n",
              "      <td>X</td>\n",
              "      <td>nus6_2_Eleutheropulos_bereinigt.txt</td>\n",
              "      <td></td>\n",
              "      <td>Nein</td>\n",
              "      <td></td>\n",
              "      <td>Denn bei der Annahme eines Rechtsgefühls wird ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7301e53-9351-4bc2-bc80-5e0cfcde91b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7301e53-9351-4bc2-bc80-5e0cfcde91b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7301e53-9351-4bc2-bc80-5e0cfcde91b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Annotator  ...                                         Textstelle\n",
              "1669         X  ...  Mit der auf breitere Basis gestellten Induktio...\n",
              "3635         X  ...  Alle diese Leute, welche von Generation zu Gen...\n",
              "434          X  ...  Wenn irgend ein Verhältnis objektiver Förderun...\n",
              "1050         X  ...  Denn je höher die Zivilisation steigt, desto m...\n",
              "626          X  ...  Mit Recht bemerkt aber Tylor1), 1) Introductio...\n",
              "3828         X  ...  Sehr bald wurde sie käuf- lich durch Versprech...\n",
              "1240         X  ...  Dafür kann die Eizelle auf Beweglichkeit verzi...\n",
              "1763         X  ...  Prinzipiell tritt er uns in zwei Formen entgeg...\n",
              "1948         X  ...  Erst jetzt sind uns aber auch die Erscheinunge...\n",
              "1793         X  ...  Denn bei der Annahme eines Rechtsgefühls wird ...\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "df = pd.DataFrame()\n",
        "\n",
        "# loading texts from these files\n",
        "including = [\"nus1_2_matzat_bereinigt.txt\", \"nus2_2_ruppin_bereinigt.txt\", \"nus3_2_schallmeyer_bereinigt.txt\", \"nus6_2_Eleutheropulos_bereinigt.txt\",\n",
        "             \"nus9_2_Haecker_bereinigt.txt\", \"nus8_2_Methner_bereinigt.txt\", \"nus5_2_Michaelis_bereinigt.txt\", \"nus7_2_Schalk_bereinigt.txt\"]\n",
        "\n",
        "# specified individual amount of new datapoints per text\n",
        "individual_amount = 500\n",
        "\n",
        "def generate_samples_txt(path,df, individual_amount, including):\n",
        "    \"\"\"\n",
        "    Generates a given amount of new non-metaphor samples from given texts and adds it to a given dataframe\n",
        "    and saves it as CSV to a given path\n",
        "    :param path: The path to save to\n",
        "    :param df: The dataframe to add to\n",
        "    :param individual_amount: The individual amount of new datapoints per text\n",
        "    :param including: The texts included in the generation process\n",
        "    :return df: The dataframe with added new metaphors\n",
        "    \"\"\"  \n",
        "    original_length = len(df)\n",
        "    for i, filename in enumerate(including):\n",
        "      print(filename)\n",
        "\n",
        "      # load text\n",
        "      file = open(os.path.join(path, filename), 'rt')\n",
        "      text = file.read()\n",
        "      text = re.sub(r'\\n+', ' ', text).strip()\n",
        "      file.close()\n",
        "\n",
        "      doc = sent_tokenize(text)\n",
        "      if len(df) > 0:\n",
        "        textstellen = df['Textstelle'].tolist()\n",
        "      else:\n",
        "        textstellen = []\n",
        "      for j, sentence in enumerate(doc):\n",
        "\n",
        "        if len(sentence) > 100 and not sentence in textstellen:\n",
        "          # check similarity to all gold standard samples via fuzzy string matching\n",
        "          tmp_df = gold_standard_df.apply(lambda row : fuzz.partial_ratio(row['Textstelle'], sentence), axis = 1)\n",
        "          max_value = tmp_df.max()\n",
        "          # take sample only if no gold standard sample has a high similarity score\n",
        "          if max_value < 60:     \n",
        "            df = df.append({'Textstelle': sentence, 'Metapher?': 'Nein', 'Fokus': '', 'Rahmen': '', 'Annotator': 'X', 'Filename': filename}, ignore_index=True)\n",
        "            if len(df) % 100 == 0:\n",
        "              print(\"Current dataframe size:\", len(df))\n",
        "        # end the generation for a specific file if individual amount is reached\n",
        "        if len(df) >= original_length+(i+1)*individual_amount:\n",
        "          break\n",
        "\n",
        "      # save the df to the given path\n",
        "      df.to_csv(ROOT_PATH+DATA_PATH+'/NoMetaphor.csv')\n",
        "      print(\"Saved Dataframe as csv.\")\n",
        "    return df\n",
        "\n",
        "# generate new non-metaphor examples from given texts and save them as CSV\n",
        "text_df = generate_samples_txt(ROOT_PATH+DATA_PATH+TEXT_PATH, df, individual_amount, including)\n",
        "\n",
        "display(text_df.sample(10))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0gaGg4rtAawy"
      ],
      "name": "DLDH_BERT_NonMetaphor_Extraction.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}